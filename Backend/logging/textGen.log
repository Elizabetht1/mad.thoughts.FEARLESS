INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 58, in generateText
    f"completion_tokens_used: {response.usage.completition_tokens} \n"
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 892, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'CompletionUsage' object has no attribute 'completition_tokens'. Did you mean: 'completion_tokens'?
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26137]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 62, in generateText
    res = response.content.choices.delta.content
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26160]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 62, in generateText
    print(response.content)
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26187]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 63, in generateText
    res = response.content.choices.delta.content
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26205]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 3 
prompt_tokens_used: 28 
total_tokens_used: 31 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 5 
prompt_tokens_used: 28 
total_tokens_used: 33 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 7 
prompt_tokens_used: 28 
total_tokens_used: 35 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 9 
prompt_tokens_used: 28 
total_tokens_used: 37 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 11 
prompt_tokens_used: 28 
total_tokens_used: 39 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 13 
prompt_tokens_used: 28 
total_tokens_used: 41 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 15 
prompt_tokens_used: 28 
total_tokens_used: 43 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 17 
prompt_tokens_used: 28 
total_tokens_used: 45 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 19 
prompt_tokens_used: 28 
total_tokens_used: 47 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 21 
prompt_tokens_used: 28 
total_tokens_used: 49 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 23 
prompt_tokens_used: 28 
total_tokens_used: 51 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 25 
prompt_tokens_used: 28 
total_tokens_used: 53 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 27 
prompt_tokens_used: 28 
total_tokens_used: 55 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 29 
prompt_tokens_used: 28 
total_tokens_used: 57 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 28 
total_tokens_used: 59 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 33 
prompt_tokens_used: 28 
total_tokens_used: 61 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 35 
prompt_tokens_used: 28 
total_tokens_used: 63 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 37 
prompt_tokens_used: 28 
total_tokens_used: 65 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 28 
total_tokens_used: 67 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 41 
prompt_tokens_used: 28 
total_tokens_used: 69 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 43 
prompt_tokens_used: 28 
total_tokens_used: 71 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 45 
prompt_tokens_used: 28 
total_tokens_used: 73 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 47 
prompt_tokens_used: 28 
total_tokens_used: 75 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 49 
prompt_tokens_used: 28 
total_tokens_used: 77 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 51 
prompt_tokens_used: 28 
total_tokens_used: 79 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 53 
prompt_tokens_used: 28 
total_tokens_used: 81 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 55 
prompt_tokens_used: 28 
total_tokens_used: 83 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 57 
prompt_tokens_used: 28 
total_tokens_used: 85 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 59 
prompt_tokens_used: 28 
total_tokens_used: 87 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 61 
prompt_tokens_used: 28 
total_tokens_used: 89 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 63 
prompt_tokens_used: 28 
total_tokens_used: 91 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 65 
prompt_tokens_used: 28 
total_tokens_used: 93 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 67 
prompt_tokens_used: 28 
total_tokens_used: 95 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 69 
prompt_tokens_used: 28 
total_tokens_used: 97 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 71 
prompt_tokens_used: 28 
total_tokens_used: 99 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 28 
total_tokens_used: 101 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 75 
prompt_tokens_used: 28 
total_tokens_used: 103 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 28 
total_tokens_used: 105 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 28 
total_tokens_used: 109 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 28 
total_tokens_used: 111 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 28 
total_tokens_used: 113 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 28 
total_tokens_used: 117 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 28 
total_tokens_used: 119 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 28 
total_tokens_used: 121 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 28 
total_tokens_used: 123 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 28 
total_tokens_used: 125 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 28 
total_tokens_used: 127 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 28 
total_tokens_used: 129 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 28 
total_tokens_used: 131 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 28 
total_tokens_used: 133 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 106 
prompt_tokens_used: 28 
total_tokens_used: 134 

INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26256]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 64, in generateText
    logger.info("potential choice from perplexity\n"+choice)
                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~
TypeError: can only concatenate str (not "Choice") to str
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26356]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello'})
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 67, in generateText
    res = response.choices[0].message['text']['content']
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
KeyError: 'text'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26377]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 3 
prompt_tokens_used: 28 
total_tokens_used: 31 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Thank', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 5 
prompt_tokens_used: 28 
total_tokens_used: 33 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' you for', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 7 
prompt_tokens_used: 28 
total_tokens_used: 35 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' reaching out', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 9 
prompt_tokens_used: 28 
total_tokens_used: 37 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='. I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 11 
prompt_tokens_used: 28 
total_tokens_used: 39 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' appreciate your', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 13 
prompt_tokens_used: 28 
total_tokens_used: 41 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' interest in', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 15 
prompt_tokens_used: 28 
total_tokens_used: 43 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' working with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 17 
prompt_tokens_used: 28 
total_tokens_used: 45 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' us.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us.'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 19 
prompt_tokens_used: 28 
total_tokens_used: 47 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Before we', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 21 
prompt_tokens_used: 28 
total_tokens_used: 49 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' proceed,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed,'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 23 
prompt_tokens_used: 28 
total_tokens_used: 51 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' could you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 25 
prompt_tokens_used: 28 
total_tokens_used: 53 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' tell me', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 27 
prompt_tokens_used: 28 
total_tokens_used: 55 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' a bit', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 29 
prompt_tokens_used: 28 
total_tokens_used: 57 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' about your', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 28 
total_tokens_used: 59 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' background and', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 33 
prompt_tokens_used: 28 
total_tokens_used: 61 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' what type', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 35 
prompt_tokens_used: 28 
total_tokens_used: 63 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' of role', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 37 
prompt_tokens_used: 28 
total_tokens_used: 65 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" you're", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 28 
total_tokens_used: 67 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' interested in', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 41 
prompt_tokens_used: 28 
total_tokens_used: 69 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='? This', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 43 
prompt_tokens_used: 28 
total_tokens_used: 71 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' will help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 45 
prompt_tokens_used: 28 
total_tokens_used: 73 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' me better', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 47 
prompt_tokens_used: 28 
total_tokens_used: 75 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' understand how', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 49 
prompt_tokens_used: 28 
total_tokens_used: 77 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' your skills', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 51 
prompt_tokens_used: 28 
total_tokens_used: 79 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' and experiences', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 53 
prompt_tokens_used: 28 
total_tokens_used: 81 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' might align', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 55 
prompt_tokens_used: 28 
total_tokens_used: 83 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' with our', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 57 
prompt_tokens_used: 28 
total_tokens_used: 85 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" company's", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 59 
prompt_tokens_used: 28 
total_tokens_used: 87 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' needs.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs."})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 61 
prompt_tokens_used: 28 
total_tokens_used: 89 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Additionally,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally,"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 63 
prompt_tokens_used: 28 
total_tokens_used: 91 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' if you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 65 
prompt_tokens_used: 28 
total_tokens_used: 93 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' have a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 67 
prompt_tokens_used: 28 
total_tokens_used: 95 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' resume or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 69 
prompt_tokens_used: 28 
total_tokens_used: 97 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' any relevant', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 71 
prompt_tokens_used: 28 
total_tokens_used: 99 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' documents,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents,"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 28 
total_tokens_used: 101 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' feel free', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 75 
prompt_tokens_used: 28 
total_tokens_used: 103 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' to share', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 28 
total_tokens_used: 105 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' them with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' me.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me."})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 28 
total_tokens_used: 109 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" Let's", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 28 
total_tokens_used: 111 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' have a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 28 
total_tokens_used: 113 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' conversation about', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' how you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 28 
total_tokens_used: 117 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' might fit', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 28 
total_tokens_used: 119 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' in here', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit in here"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 28 
total_tokens_used: 121 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason='stop', index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit in here."})
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26401]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 28 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but let's take a moment to discuss your qualifications and how they might align with our current or future opportunities. Could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, have you had a chance to look at our company's current job postings or would you like some information on how to apply for positions that might be a good fit for you?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 28, in generate_conversation
    questionText = textGen.generateText(
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 66, in generateText
    res = response.choices[0].message['content']
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
TypeError: 'ChatCompletionMessage' object is not subscriptable
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26465]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 288 
prompt_tokens_used: 28 
total_tokens_used: 316 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through some strategies to help you find a job that suits your skills and interests.\n\nCould you tell me a bit about your background, skills, and what kind of job you're looking for? This will help me provide more tailored advice.\n\nAdditionally, here are some general tips that might be helpful:\n\n1. **Gather Your Information**: Make sure you have all your work history, skills, education, and references ready. This will help you prepare a strong resume and cover letter[1].\n\n2. **Search Online**: Use job search engines like LinkedIn, Indeed, and Glassdoor to find opportunities that match your criteria[1].\n\n3. **Network**: Share your job search with friends and family, and consider attending job fairs or networking events[1].\n\n4. **Consider What You Love**: Think about what motivates you and what kind of work environment you prefer. This can help you find a job that you'll truly enjoy[2].\n\n5. **Develop Your Skills**: If you're looking to transition into a new field, consider taking courses or getting certifications to enhance your skills[2].\n\nLet's discuss these points further and see how they might apply to your situation. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26536]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 28 
total_tokens_used: 110 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit more about yourself and what kind of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, have you had a chance to look at our current job openings or is there a specific position you're hoping to explore?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 15, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: pplx-rKV*****************************************LC9b. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [27739]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 168 
prompt_tokens_used: 28 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I don't have the authority to offer you a job directly. Instead, I can guide you through some strategies that might help you find a suitable position.\n\nFirst, let's talk about your skills and interests. What type of job are you looking for? Have you considered any specific industries or roles that align with your strengths and passions?\n\nAdditionally, have you prepared a resume and cover letter? These are essential tools for applying to jobs. If you need help with those, I can provide some tips or resources.\n\nLastly, networking can be very effective. Have you connected with anyone in your desired field or attended any job fairs recently?\n\nLet's explore these areas further and see how we can assist you in your job search.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.467762 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.798412 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 15, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1049, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1098, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1049, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1098, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 308 
prompt_tokens_used: 28 
total_tokens_used: 336 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I'm glad you're interested in exploring opportunities with us. However, I'd like to clarify that we typically follow a structured process for hiring. This involves reviewing resumes, conducting interviews, and assessing candidates based on specific job requirements.\n\nBefore we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me understand how your skills and interests might align with our current openings. Additionally, I can provide you with some tips on how to find job opportunities that might be a good fit for you.\n\nHere are some general tips that might be helpful:\n\n1. **Gather Your Information**: Make sure you have all your work history, skills, education, and references ready. This will help you tailor your applications to specific job openings[1].\n\n2. **Search Online**: Use job search engines like LinkedIn, Indeed, and Glassdoor to find opportunities that match your skills and interests[1].\n\n3. **Network**: Let your friends, family, and community know you're looking for a job. They might have connections that can help[1].\n\n4. **Consider Your Passion**: Think about what you enjoy doing and look for roles that align with those interests[2].\n\n5. **Develop Your Skills**: Take courses or get certifications to enhance your qualifications for the jobs you're interested in[2].\n\nLet's discuss how these strategies might apply to your situation. What are your strengths and what kind of job are you hoping to find?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 324, in jsonable_encoder
    data = dict(obj)
           ^^^^^^^^^
TypeError: '_ssl._SSLSocket' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 329, in jsonable_encoder
    data = vars(obj)
           ^^^^^^^^^
TypeError: vars() argument must have __dict__ attribute

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 332, in jsonable_encoder
    raise ValueError(errors) from e
ValueError: [TypeError("'_ssl._SSLSocket' object is not iterable"), TypeError('vars() argument must have __dict__ attribute')]
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [27830]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I appreciate your enthusiasm, but let's take a moment to discuss the position and how you might be a good fit. Could you tell me a bit about your background and what skills you think would make you suitable for a role here? Additionally, what kind of job are you interested in, and what do you know about our company? This will help us have a more productive conversation.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 324, in jsonable_encoder
    data = dict(obj)
           ^^^^^^^^^
TypeError: '_ssl._SSLSocket' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 329, in jsonable_encoder
    data = vars(obj)
           ^^^^^^^^^
TypeError: vars() argument must have __dict__ attribute

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 332, in jsonable_encoder
    raise ValueError(errors) from e
ValueError: [TypeError("'_ssl._SSLSocket' object is not iterable"), TypeError('vars() argument must have __dict__ attribute')]
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28066]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 115 
prompt_tokens_used: 28 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might be a good fit for you.\n\nCould you tell me a bit about your background, skills, and what type of job you're interested in? This will help me provide you with more tailored advice or resources. Additionally, have you considered using job search platforms like LinkedIn or Indeed to explore available positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('test')
            ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named 'test' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28253]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 28 
total_tokens_used: 106 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. However, before we proceed, could you please tell me a bit about yourself? What kind of role are you interested in, and what skills or experiences do you think would make you a strong candidate for our company? This will help me better understand how we might be able to assist you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('./generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named './generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28286]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable in a position here?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('./generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named './generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28329]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 28 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. However, I'd like to discuss your qualifications and how they align with our current or future opportunities. Could you please tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how your skills and interests might fit into our organization.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named 'generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28351]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 124 
prompt_tokens_used: 28 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm for working with us. However, I'd like to discuss a few things before we proceed. Could you tell me a bit about your background and what kind of role you're interested in? This will help me better understand how your skills might align with our company's needs.\n\nAlso, if you have a resume or any relevant experience, it would be great if you could share that with me. This will give us a solid foundation for our conversation.\n\nLet's chat more about what you're looking for and how you think you could contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.455468 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28377]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 109 
prompt_tokens_used: 28 
total_tokens_used: 137 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me better understand how you might fit into our organization.\n\nAlso, if you have a resume or any relevant experience, feel free to share that with me. It's always helpful to have a clear picture of your qualifications and skills.\n\nLet's have a conversation about your career goals and how they align with our company's opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 31, in generateAudio
    bytes = fin.read()
            ^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa9 in position 10: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28487]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 150 
prompt_tokens_used: 28 
total_tokens_used: 178 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I understand that you're looking for a job, and I'm happy to discuss potential opportunities with you. However, I need to clarify that we typically follow a formal hiring process. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, have you had a chance to look at our company's job listings or any specific positions that align with your interests? We can discuss those further if you'd like. \n\nLet's start with your qualifications and what you're looking for in a job. That way, we can explore if there's a good fit here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28567]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 164 
prompt_tokens_used: 28 
total_tokens_used: 192 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I appreciate your enthusiasm, but let's take a moment to discuss your qualifications and how they align with our current job openings. Could you tell me a bit about your background, skills, and what you're looking for in a role? This will help me understand how you might fit into our organization. \n\nAlso, I'd like to share some general advice on job searching. It's important to tailor your resume and cover letter to the specific job you're applying for, and to be prepared to talk about your skills and experiences during an interview. Networking and attending job fairs can also be very beneficial. \n\nIf you have any questions about our company or the positions available, feel free to ask. Let's have a conversation about how you can contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28646]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 117 
prompt_tokens_used: 28 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I don't have the authority to offer jobs directly. Instead, I can guide you through the process of finding a job that might be a good fit for you.\n\nCould you tell me a bit about your background, skills, and what type of job you're interested in? This will help me provide more tailored advice or suggestions. Additionally, have you considered using job search platforms like LinkedIn or Indeed, or networking with people in your desired field?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28694]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 28 
total_tokens_used: 124 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you please tell me a bit about your background and what kind of role you're interested in? This will help me better understand how we might be able to assist you.\n\nAlso, have you had a chance to look at our current job postings or is there a specific department or position you're interested in? Let's chat more about your qualifications and interests.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28730]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 123 
prompt_tokens_used: 28 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable in a position here? \n\nAlso, have you had a chance to look at our company's current job postings or are you interested in exploring possibilities that might not be listed? Let's chat more about how your skills and interests align with our organization.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.469694 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28757]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 28 
total_tokens_used: 129 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to have a more structured conversation about potential opportunities. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how you might fit into our organization. Additionally, if you have a resume or any relevant projects you'd like to share, that would be great. Let's discuss how your skills and interests align with our company's needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28815]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 121 
prompt_tokens_used: 28 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to take a moment to discuss how we typically approach hiring here. We usually look for candidates who have a strong fit with the role and our company culture. Could you tell me a bit about your background and what makes you interested in working with us? This will help me understand how your skills and experiences align with our current or future opportunities. \n\nAlso, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28911]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 28 
total_tokens_used: 126 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to have a more structured conversation about potential opportunities. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how you might fit into our organization. Additionally, if you have a resume or any relevant experience, feel free to share that as well. Let's discuss how your qualifications align with our current or future needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29036]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 149 
prompt_tokens_used: 28 
total_tokens_used: 177 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can provide guidance on how to find job openings and prepare for interviews.\n\nCould you tell me a bit about your background and what kind of job you're interested in? This will help me provide more tailored advice. Additionally, have you considered using job search platforms like Indeed or LinkedIn to explore available positions? \n\nIf you're new to job searching or need to improve your resume or interview skills, there are many resources available online, such as career counseling services and free training programs. Let's discuss how these might be helpful for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 1982: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29076]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 123 
prompt_tokens_used: 28 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I'm happy to chat with you about potential opportunities. However, I'd like to start by getting to know you a bit better. Could you tell me a little about your background, what you're interested in, and what kind of role you're looking for? This will help me understand how we might be able to assist you. \n\nAlso, have you had a chance to explore our company's culture and values? We're always looking for individuals who align well with our mission. Let's have a conversation about how your skills and interests might fit in here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 2126: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29109]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 119 
prompt_tokens_used: 28 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential job opportunities with you. However, I need to clarify that I'm not in a position to offer a job directly at this moment. Instead, I can guide you through the process of finding a job or preparing for an interview.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice or suggestions for you. Additionally, have you considered using job search platforms like LinkedIn, Indeed, or Glassdoor to explore available positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 25, in generateAudio
    exit()
  File "<frozen _sitebuiltins>", line 26, in __call__
SystemExit: None
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29163]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 128 
prompt_tokens_used: 28 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I don't have the authority to offer jobs directly. Instead, I can guide you through the process of finding a job or preparing for interviews.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice or suggestions on where to look for job openings that might suit you. Additionally, I can offer tips on how to improve your resume, cover letter, or interview skills if needed. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 25, in generateAudio
    exit()
  File "<frozen _sitebuiltins>", line 26, in __call__
SystemExit: None
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29218]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 194 
prompt_tokens_used: 28 
total_tokens_used: 222 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might suit your skills and interests.\n\nCould you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that might be relevant? This will help me provide you with more tailored advice or resources. \n\nAdditionally, have you considered using job search platforms like Indeed, LinkedIn, or Glassdoor? These sites can be very helpful in finding job openings that match your criteria. \n\nIf you're new to job searching or need more experience, there are also resources available for training and volunteering, which can be great ways to gain experience and build your network. \n\nLet's discuss these options further and see how I can assist you in your job search", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29243]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 133 
prompt_tokens_used: 28 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through some strategies that might help you in your job search.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice. Additionally, have you considered using job search platforms like LinkedIn or Indeed, or perhaps attending job fairs to network with potential employers? \n\nLet's discuss these options and see how we can best support your job search efforts.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 34, in generateAudio
    print(response.contet)
          ^^^^^^^^^^^^^^^
AttributeError: 'HttpxBinaryResponseContent' object has no attribute 'contet'. Did you mean: 'content'?
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29319]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 145 
prompt_tokens_used: 28 
total_tokens_used: 173 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable to our organization? \n\nAlso, have you had a chance to look at our company's current job listings or would you like some information on those? Sometimes, we have positions that aren't listed publicly yet, so it's always good to check in directly. \n\nLet's chat more about your qualifications and interests, and we can explore if there's a good fit here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29350]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 113 
prompt_tokens_used: 28 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to get to know you better and understand what you're looking for in a role. Could you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me see how we might be able to assist you. \n\nAlso, have you had a chance to explore our company's current job openings or is there a specific department you're interested in? Let's discuss how your skills and interests align with what we do here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29383]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 172 
prompt_tokens_used: 28 
total_tokens_used: 200 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm. However, I'd like to discuss your qualifications and how they might align with our company's needs. Could you tell me a bit about your background and what kind of role you're interested in? This will help us determine if there's a good fit for you within our organization. Additionally, if you have a resume or any relevant experience, feel free to share that as well. Let's have a conversation about how you can contribute to our team. \n\nAlso, if you're interested in learning more about how to approach job applications, I can offer some general advice. For instance, it's often helpful to tailor your application to the specific job you're applying for and to highlight your relevant skills and experiences. If you have any questions or need guidance on that, feel free to ask", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29433]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 127 
prompt_tokens_used: 28 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need a bit more information from you to see how we might be able to assist you. Could you please tell me a little bit about your background, skills, and what type of job you're interested in? This will help me better understand how we can support you in your job search. \n\nAlso, have you considered creating a resume or cover letter, or perhaps looking into job search platforms like LinkedIn or Indeed? These tools can be very helpful in finding job openings that match your qualifications. Let's discuss further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.382049 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29484]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 120 
prompt_tokens_used: 28 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might suit your skills and interests.\n\nCould you tell me a bit about your background, what kind of job you're looking for, and what skills or experiences you have? This will help us explore options together. Additionally, I can provide some tips on how to effectively search for jobs and prepare for interviews. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29733]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 141 
prompt_tokens_used: 24 
total_tokens_used: 165 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help and support you in your search.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to exploring different industries or do you have a specific sector in mind? \n\nLastly, what do you hope to achieve in your next role? Is there something particular that you're looking for, like work-life balance, opportunities for growth, or a certain work environment? \n\nLet's chat about these things and see how we can help you find a great fit", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 24 
total_tokens_used: 118 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any specific industries you're interested in? This will help me understand how I can assist you better. \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? Knowing this can help us explore more options together.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 24 
total_tokens_used: 110 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help and support you in your search.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are there any specific industries or roles that interest you? This will help us explore potential opportunities together.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 24 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and provide guidance.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help us narrow down some options and discuss potential paths forward.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 24 
total_tokens_used: 134 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly, let's have a conversation about your job aspirations. I'm here to help facilitate a discussion about your career goals and how we might be able to assist you in finding a suitable position.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate for that role? \n\nAlso, are there any specific industries or sectors that interest you? This will help us narrow down potential opportunities that might be a good fit for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 60 
prompt_tokens_used: 24 
total_tokens_used: 84 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Let's have a friendly conversation about your job search. I'm here to help you explore opportunities that might be a good fit for you.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for? Are there any specific industries or roles that interest you?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [45479]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 160 
prompt_tokens_used: 24 
total_tokens_used: 184 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n---\n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're interested in? Are there any specific industries or roles that appeal to you?\n\n**Follow-up Questions:**\n1. What skills do you think are your strongest assets for a job?\n2. Are you open to different types of work environments, such as remote or in-office positions?\n3. What are your long-term career goals, and how does this job fit into your overall vision?\n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47059]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 24 
total_tokens_used: 125 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in finding the right opportunity.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for, and what skills or experiences do you have that you think would be valuable in a role?\n\nAlso, are there any specific industries or sectors that interest you? This will help us narrow down some options and explore potential job openings that might be a good fit for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47277]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 106 
prompt_tokens_used: 24 
total_tokens_used: 130 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly Let\'s have a friendly conversation about job opportunities. I\'d love to hear more about what you\'re looking for in a role. Could you tell me a bit about your interests and skills? Are you open to different types of positions, or do you have something specific in mind? \n\nAlso, I noticed there are various "Pretty Please" related job listings available, such as those at Pretty Please Boutique or Pretty Please Collective. Are any of these roles or industries appealing to you? Let\'s explore some options together', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 166 
prompt_tokens_used: 24 
total_tokens_used: 190 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly I'd be happy to engage in a mock interview with you. Let's get started!\n\n---\n\n**Interviewer:** Good morning, thank you for coming in today. Can you start by telling me a little bit about yourself and why you're interested in this role?\n\n**Please respond as the interviewee.**\n\n---\n\nAfter your response, I can guide the conversation further based on your interests and qualifications. \n\nAlso, if you're interested in specific job openings, I can provide some general information. For example, **Pretty Please Fashion** has positions available in locations like Palm Desert and Coronado, California, and Scottsdale, Arizona[1]. If you're looking for something different, there are also various **Pretty Please Boutique** jobs listed on job boards[2]. Let me know how I can assist you", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 126 
prompt_tokens_used: 24 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. \n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're looking for? What are your interests and skills that you think would be valuable in a role?\n\n**Follow-up Questions:**\n1. What specific industry or sector are you interested in?\n2. Do you have any relevant experience or education that aligns with your job goals?\n3. Are you open to different types of work environments, such as remote or in-office positions?\n\nLet's explore these questions together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47332]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 24 
total_tokens_used: 112 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're interested in? What skills or experiences do you think would make you a strong candidate for a position? \n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help me better understand how I can assist you in finding a job that suits your interests and skills.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47502]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/speechAPI.py", line 30, in generate_conversation
    questionText = textGen.generateText(
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/utils/textGen.py", line 50, in generateText
    response = client.chat.completions.create(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: <html>
<head><title>401 Authorization Required</title></head>
<body>
<center><h1>401 Authorization Required</h1></center>
<hr><center>openresty/1.25.3.1</center>
<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'90ee96ef2d5e1167',t:'MTczOTA0ODg0OS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
</html>
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [6756]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/speechAPI.py", line 30, in generate_conversation
    questionText = textGen.generateText(
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/utils/textGen.py", line 50, in generateText
    response = client.chat.completions.create(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: <html>
<head><title>401 Authorization Required</title></head>
<body>
<center><h1>401 Authorization Required</h1></center>
<hr><center>openresty/1.25.3.1</center>
<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'90ee97970c2661a2',t:'MTczOTA0ODg3Ni4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
</html>
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [6916]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 62 
prompt_tokens_used: 24 
total_tokens_used: 86 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any relevant experiences you have? This will help me understand how I can assist you in finding the right opportunity.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 139 
prompt_tokens_used: 24 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help and provide information that might be useful to you.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that you think would be relevant? Are you interested in a specific industry or role? \n\nAlso, are you open to different locations, or do you have a preference for a particular area? \n\nLastly, what are your long-term career goals, and how does this job fit into your overall vision? \n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50179]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 24 
total_tokens_used: 122 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help facilitate a mock interview or discuss potential job opportunities. Could you tell me a bit about yourself and what kind of job you're interested in? This will help us tailor the conversation to your needs and interests. \n\nAlso, are there any specific industries or roles you're considering? This could be anything from retail, tech, healthcare, or something else entirely. Let me know, and we can explore options together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50303]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 125 
prompt_tokens_used: 24 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Let's have a friendly conversation about your job search. I'm here to help you explore opportunities that might fit your skills and interests.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or roles that interest you? For example, some people are interested in creative fields like design or writing, while others might prefer more technical roles like engineering or data analysis.\n\nLastly, are you open to different types of work arrangements, such as remote work or part-time positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Finished server process [50330]
ERROR:uvicorn.error:Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1512, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1505, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1379, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 557, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 476, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/server.py", line 69, in serve
    with self.capture_signals():
         ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/server.py", line 330, in capture_signals
    signal.raise_signal(captured_signal)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 157, in _on_sigint
    raise KeyboardInterrupt()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 700, in lifespan
    await receive()
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/lifespan/on.py", line 137, in receive
    return await self.receive_queue.get()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/queues.py", line 158, in get
    await getter
asyncio.exceptions.CancelledError

INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 24 
total_tokens_used: 106 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course, let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n**Can you tell me a bit about yourself? What kind of job are you interested in?**\n\nAlso, are there any specific industries or roles that you've been considering? This will help us tailor our conversation to your interests and goals.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50380]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 24 
total_tokens_used: 126 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in any way I can.\n\n**Can you tell me a little bit about yourself?** What kind of job are you looking for, and what skills or experiences do you have that you think would be relevant?\n\nAlso, **what motivates you** in your career, and **what kind of work environment** do you prefer? This will help me understand your needs better and provide more tailored advice.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50480]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 131 
prompt_tokens_used: 24 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. I'm here to help you explore potential roles that might suit your skills and interests.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that you think would be valuable in a role? \n\nAlso, are you open to different types of positions, such as part-time, full-time, or freelance work? \n\nLastly, is there a specific industry or sector that interests you the most? \n\nLet's chat about these details to see how we can help you find a job that fits your needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50501]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 127 
prompt_tokens_used: 24 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a career.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you have that you think would be valuable in that role?\n\nAlso, are you open to different types of positions, such as part-time, full-time, or freelance work? And are there any specific industries or sectors that interest you? \n\nLet's chat about your goals and see how we can help you find a job that fits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50548]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 24 
total_tokens_used: 124 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any specific industries you're interested in? This will help me understand how I can assist you better. \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? And are there any specific locations you prefer? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50609]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 149 
prompt_tokens_used: 24 
total_tokens_used: 173 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Here are a few questions to get us started:\n\n1. **What type of job are you looking for?** Are you interested in a specific industry or role?\n\n2. **What skills do you have?** Share any relevant skills or experiences you think would be valuable in a job.\n\n3. **What are your long-term career goals?** Are there any specific positions or industries you hope to be in five years from now?\n\n4. **Are you open to different locations?** Would you prefer to work in a specific city or are you flexible about moving?\n\nLet's chat about these points and see how we can help you find a job that fits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50660]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 70 
prompt_tokens_used: 24 
total_tokens_used: 94 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51040]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 197 
prompt_tokens_used: 1197 
total_tokens_used: 1394 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're looking for a job, and I can provide some guidance on where to find opportunities. Here are a few options:\n\n1. **Pretty Please Fashion**:\n   - They have a few job openings, including a **Hat Artist** in Palm Desert, CA, and a **Store Manager** in Coronado, CA. Another position is for a **Delivery Driver/Warehouse** in Scottsdale, AZ[1].\n\n2. **Pretty Please Aesthetics**:\n   - Currently, they are not hiring, but you can submit your resume for future consideration. They are based in Sacramento and Roseville[3].\n\n3. **General Job Search**:\n   - You can explore a wide range of jobs on platforms like Indeed, which lists numerous positions across different industries, including retail, beauty, and more[2].\n\nIf you're interested in a specific field or location, you might want to tailor your search accordingly. Good luck with your job search", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51379]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 147 
prompt_tokens_used: 24 
total_tokens_used: 171 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in finding the right opportunity.\n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're looking for? What are your interests and skills that you think would be valuable in a role?\n\n**Follow-up Questions:**\n- What specific industry or sector are you interested in?\n- Do you have any previous work experience or education that you think is relevant?\n- Are there any particular skills or areas you'd like to develop further in your career?\n\nLet's chat about these and see how we can help you find a job that fits your goals", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51395]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 194 
prompt_tokens_used: 24 
total_tokens_used: 218 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Here's how we can approach this:\n\n1. **Introduction**: Could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you bring to the table?\n\n2. **Job Preferences**: Are you looking for something specific, like a role in a particular industry or a certain type of work environment?\n\n3. **Skills and Strengths**: What are your greatest strengths and skills that you think would be valuable in a job?\n\n4. **Career Goals**: What are your long-term career goals, and how does this job fit into your overall vision?\n\n5. **Availability and Flexibility**: Are you available to start immediately, or do you have specific timing in mind? Are you open to different types of employment, such as part-time or freelance work?\n\nLet's explore these questions together to see how we can find a good fit for you", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51473]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 156 
prompt_tokens_used: 24 
total_tokens_used: 180 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help facilitate a discussion that might lead to some insights or opportunities.\n\n## Conversation Starters\n\n1. **Background and Interests**: Could you tell me a bit about your educational background and what kind of work or industry you're interested in?\n\n2. **Skills and Experience**: What skills or experiences do you think would be most valuable in your desired role?\n\n3. **Job Preferences**: Are you looking for something specific like remote work, part-time, or full-time opportunities?\n\n4. **Career Goals**: What are your short-term and long-term career goals?\n\n5. **Available Opportunities**: Are there any specific job openings or companies you've been considering?\n\nLet's explore these topics together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51651]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 173 
prompt_tokens_used: 24 
total_tokens_used: 197 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. I'd like to explore what kind of role you're interested in and see if there's a good fit.\n\n1. **What type of job are you looking for?** Are you interested in a specific industry or role, such as retail, tech, or something creative?\n\n2. **What skills do you bring to the table?** Highlighting your strengths and experiences can help us narrow down potential opportunities.\n\n3. **Are you open to different locations?** Some jobs might require relocation or remote work. Let's discuss your preferences.\n\n4. **What are your long-term career goals?** Understanding where you want to be in the future can help guide our conversation about current opportunities.\n\nLet's chat about these points and see how we can assist you in finding a job that suits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51689]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 24 
total_tokens_used: 114 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore potential opportunities.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to different types of roles or industries, or do you have something specific in mind? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51757]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 172 
prompt_tokens_used: 24 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help facilitate a mock interview or discuss job opportunities with you. How can I assist you today? Are you looking for advice on finding a job, or would you like to practice an interview scenario? \n\nHere are a few options we could explore:\n\n1. **Job Search Tips**: We could discuss strategies for finding the right job, including resume building, networking, and interview preparation.\n   \n2. **Mock Interview**: If you're preparing for an interview, we can simulate a real interview scenario. This can help you practice answering common interview questions and improve your confidence.\n\n3. **Career Advice**: If you're unsure about which career path to take, we can explore different fields and discuss what might be a good fit for you.\n\nLet me know which direction you'd like to take", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52162]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 24 
total_tokens_used: 122 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities that might be a good fit for you.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help us narrow down some options that might suit you well.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 60, in transcribe_user_speech
    transcription = audioStore.transcribeAudio(f"./user_audio_files/{file.filename}")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioStore.py", line 35, in transcribeAudio
    phrases = silence.split_on_silence(audio, min_silence_len=600, silence_thresh=-32)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 150, in split_on_silence
    in detect_nonsilent(audio_segment, min_silence_len, silence_thresh, seek_step)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 86, in detect_nonsilent
    silent_ranges = detect_silence(audio_segment, min_silence_len, silence_thresh, seek_step)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 26, in detect_silence
    silence_thresh = db_to_float(silence_thresh) * audio_segment.max_possible_amplitude
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'numpy.ndarray' object has no attribute 'max_possible_amplitude'
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 131 
prompt_tokens_used: 24 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help facilitate a discussion that might lead to some great opportunities.\n\nTo start, could you tell me a bit about yourself? What kind of job or industry are you interested in? What skills or experiences do you bring to the table? \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? \n\nLastly, what are your long-term career goals, and how does this job fit into your overall vision? \n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52213]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 24 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help you explore potential job opportunities. Could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? \n\nAlso, are you open to different types of roles or industries, or do you have something specific in mind? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52410]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 24 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or sectors that interest you? This could help us narrow down some potential opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 60, in transcribe_user_speech
    transcription = audioStore.transcribeAudio(f"./user_audio_files/{file.filename}")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioStore.py", line 63, in transcribeAudio
    phrase.export(phrase_audio_file_path, bitrate='256k', format="wav")
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/audio_segment.py", line 867, in export
    out_f, _ = _fd_or_path_or_tempfile(out_f, 'wb+')
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/utils.py", line 60, in _fd_or_path_or_tempfile
    fd = open(fd, mode=mode)
         ^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../phrases/phrase0.wav'
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 24 
total_tokens_used: 117 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to different types of positions or industries, or do you have something specific in mind?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52444]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 276 
prompt_tokens_used: 24 
total_tokens_used: 300 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. Here's a neutral and engaging approach:\n\n---\n\n**Interviewer:** Hi there Thank you for coming in today. I understand you're looking for a job, and I'd be happy to help explore some options with you. Can you tell me a bit about yourself and what kind of job you're interested in?\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Follow-up:** That sounds great Let's see if we can match your skills and interests with some available positions. Are you open to working in different industries, or do you have a specific sector in mind?\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Follow-up:** Excellent Based on what you've shared, I think we might have a few opportunities that could be a good fit. Let me show you some job listings that might interest you. (Present some relevant job listings)\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Conclusion:** It was great chatting with you If you have any more questions or would like to proceed with any of these opportunities, feel free to let me know. We're here to help.\n\n---\n\nThis approach is designed to be friendly and exploratory, helping to identify the interviewee's interests and skills while offering support in finding a suitable job.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52520]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 1216 
total_tokens_used: 1255 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your sentence is incomplete or unclear. Could you please provide more context or clarify what you are trying to express? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 36 
prompt_tokens_used: 1207 
total_tokens_used: 1243 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking for? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 1207 
total_tokens_used: 1238 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking? I'll do my best to assist you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52737]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 82 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello It's great to meet you. You're a computer science major looking for employment opportunities, and you're here today to explore potential job openings with our company. You seem eager to find a position that aligns with your skills and interests.\n\nTo summarize, you've expressed your enthusiasm for being employed and are hoping to find a suitable role within our organization. Let's take a moment to discuss your background and how your skills might fit into our current projects. Can you tell me a bit more about your experiences and what you're most interested in working on?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52839]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 153 
prompt_tokens_used: 72 
total_tokens_used: 225 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It sounds like you're preparing for a speaking engagement and are concerned about enunciating well as you're also in the process of job hunting. You're asking if I can transcribe your audio, possibly to help you review your speech or improve your delivery.\n\nTo address your request, there are several options available for transcribing audio. You could consider using services like TranscribeMe, Scribie, or Otter.ai, which offer high-quality transcription services. Alternatively, if you prefer to do it yourself, there are free tools like OTranscribe or Express Scribe that you can use.\n\nLet's focus on how you're feeling about your speaking engagement and job search. How do you think transcribing your audio might help you prepare or improve your performance?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52974]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 57 
total_tokens_used: 162 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're interested in discussing debugging queries, possibly in the context of database management or other systems. Could you please elaborate on what specific aspect of debugging queries you'd like to explore? Are you looking at SQL queries, debugging tools like Chalk, or perhaps issues with chatbot responses in platforms like Yext? This will help me better understand your query and provide a more tailored response. \n\nTo summarize, you seem to be asking about debugging queries, but I'd like more details to assist you effectively.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [53040]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 54 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It sounds like you're concerned about an issue related to audio files. You mentioned that you think there might be a problem with how audio files are handled, and you're worried that things are moving quickly. Could you elaborate a bit more on what specifically is causing your concern? What kind of issues are you experiencing with audio files? \n\nTo summarize, you believe there's an issue with audio files, possibly related to their handling or playback, and you're feeling a sense of urgency about it.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [53094]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 181 
prompt_tokens_used: 55 
total_tokens_used: 236 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It sounds like you\'re expressing a bit of self-deprecation, which is a common way people use humor or humility to connect with others. You mentioned hoping your contribution helps, but then you jokingly attributed any potential shortcomings to your own incompetence. This kind of self-deprecation can be a way to appear more relatable or likable by acknowledging potential flaws in a lighthearted manner.\n\nTo continue the conversation, I might say something like: "Thank you for sharing that. It\'s great that you\'re willing to be open and honest. Can you tell me more about what you\'re hoping to achieve or discuss today?" This approach acknowledges their sentiment while gently steering the conversation forward. \n\n**Summary of what you said:**\n- You\'re hoping your contribution will be helpful.\n- You jokingly referred to yourself as incompetent, using self-deprecation as a form of humor or humility.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [53184]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 57 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re emphasizing that this is a final test. Could you elaborate on what you mean by "this is one final test"? Are you referring to a specific examination or assessment, or is there another context you\'d like to discuss?\n\nTo summarize, you\'ve stated that there is a final test, but you haven\'t specified the nature or context of this test. If you could provide more details, I\'d be happy to engage further in the conversation.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [53255]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and polite way.\n\nTo summarize, you\'re seeking a job and are open to suggestions or assistance in finding one. Is there a specific type of job or industry you\'re interested in? Or would you like some general advice on where to start your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54633]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 80 
prompt_tokens_used: 58 
total_tokens_used: 138 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner, saying "give me a job pretty please." You\'re expressing a desire for employment, possibly looking for assistance or guidance in finding a suitable position. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in a friendly manner. You\'ve said, "Give me a job pretty please." Let\'s have a conversation about your interests and qualifications. Could you tell me a bit about yourself, such as your education background, skills, or any specific job roles you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." Let\'s break this down:\n\n- **Request for a Job**: You\'re expressing a desire to be employed.\n- **Polite Tone**: You\'re using a polite and friendly approach by saying "pretty please," which indicates a respectful and hopeful attitude.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54736]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly manner.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54838]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Let's have a more formal conversation about your job interests and qualifications. Could you tell me a bit about your background, skills, and what kind of job you're looking for? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specific details yet. Let's explore your options together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54878]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a friendly tone. Could you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand your needs and provide more tailored advice.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 80 
prompt_tokens_used: 58 
total_tokens_used: 138 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job, and you're saying it in a polite manner. Let's break it down:\n\n- **Your Request**: You're asking for a job opportunity, using a friendly and polite tone.\n- **Current Situation**: You haven't mentioned your current situation or what kind of job you're looking for.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you're interested in? This will help me provide more tailored advice or suggestions.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said: You\'re asking for a job, and you\'re using a polite and somewhat playful tone by saying "pretty please."\n\nNow, let\'s discuss potential job opportunities. Are you looking for a specific type of job or industry? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. Let me summarize what you\'ve said:\n\n- You\'re interested in obtaining a job.\n- You\'ve added a polite phrase, "pretty please," to your request.\n\nCould you tell me a bit more about the type of job you\'re interested in or any specific skills you have? This will help me better understand your needs and provide more relevant information.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 126 
prompt_tokens_used: 58 
total_tokens_used: 184 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Let me summarize what you\'ve said: You\'re expressing a polite request for a job opportunity. However, I don\'t have specific job openings at "Pretty Please" to offer you right now. If you\'re interested in exploring opportunities in related fields or discussing your qualifications, I\'d be happy to engage in a conversation about potential job paths or how to prepare for future openings. \n\nCould you tell me a bit more about your background or what kind of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54887]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 157 
prompt_tokens_used: 58 
total_tokens_used: 215 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in finding one. You\'ve said, "Give me a job pretty please." Let\'s break down what you\'re looking for:\n\n1. **Job Type**: You haven\'t specified a particular job type, so we can explore various options.\n2. **Location**: You haven\'t mentioned a preferred location, so we can consider both local and remote opportunities.\n3. **Skills**: You haven\'t listed specific skills, but we can discuss what you\'re interested in or have experience with.\n\nTo help you better, could you tell me a bit more about your interests, skills, or any previous experience you have? This will allow us to narrow down some job options that might suit you well.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54946]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand what you're looking for. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your qualifications and preferences to find a suitable opportunity.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [54992]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 58 
total_tokens_used: 139 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and courteous way.\n\nTo better assist you, could you tell me a bit more about the type of job you\'re interested in? Are you looking for something specific in terms of industry or role?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 58 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." You\'re expressing a polite and enthusiastic request for employment. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a position? This will help me better understand your needs and provide more tailored advice. \n\nTo summarize, you\'re looking for a job and are eager to explore opportunities. Is there a specific industry or role that interests you?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 58 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you mentioned "Pretty Please." Could you clarify what kind of job you\'re interested in? Are you looking for something specific within the beauty and wellness industry, or perhaps something else?\n\nTo summarize, you\'ve expressed interest in a job and mentioned "Pretty Please," which seems to be related to a company or brand in the beauty and wellness sector. Let\'s discuss further to understand your career aspirations and how they align with available opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to assist you in finding one. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for some guidance or assistance in your job search.\n\nCould you tell me a bit more about yourself? What kind of job are you interested in? What skills or experiences do you have that might be relevant to your desired role?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 393 
prompt_tokens_used: 1218 
total_tokens_used: 1611 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are some job opportunities and trends that might interest you:\n\n## In-Demand Jobs for 2025\n\n1. **Data Scientists**: These professionals analyze data to predict trends and are in high demand due to the increasing need for data-driven decision-making. The median wage for data scientists is around $51.93 per hour, with a projected growth of 9% by 2033[1][5].\n\n2. **AI Specialists**: With advancements in AI, specialists in this field are increasingly sought after. AI skills are crucial for businesses adapting to technological changes[5].\n\n3. **Customer Service Representatives**: These roles often offer flexible hours and remote work options, making them appealing for those seeking work-life balance. The median wage is about $19.08 per hour[1].\n\n4. **Baristas**: As coffee remains a popular beverage, barista positions are available, especially in larger coffee chains that offer benefits like health coverage[1].\n\n5. **Bicycle Repairers**: With more bike lanes being built, the demand for bicycle mechanics is growing. On-the-job training is often available[1].\n\n## Job Openings at Pretty Please Boutique\n\nIf you\'re interested in retail or related fields, there are numerous job openings available at boutiques and similar establishments. However, specific openings at "Pretty Please Boutique" are not detailed in the search results. You might find similar roles in retail sales or related positions on job boards like Indeed[4].\n\n## General Job Search Tips\n\n- **Networking**: Use platforms like AnandTech forums to connect with professionals who might be able to assist in your job search[2].\n- **Upskilling**: The World Economic Forum emphasizes the need for continuous skill development, especially in technology and human skills, to remain competitive in the job market[3].\n- **Flexibility**: Be open to different locations and types of roles, as some positions offer flexible schedules or remote work options[1][4].', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted manner. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? That would help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you tell me a bit more about what kind of job you're interested in or what skills you have to offer? This will help me better understand your request and provide more relevant assistance. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 104 
prompt_tokens_used: 58 
total_tokens_used: 162 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo summarize, you\'re expressing interest in finding a job, and I\'m here to help facilitate that conversation. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 133 
prompt_tokens_used: 58 
total_tokens_used: 191 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re looking for? Are you interested in a specific industry or role? Additionally, I noticed that there are some job listings related to "Pretty Please" on Indeed, but it seems they might not be directly related to your query. Could you provide more details about what you\'re looking for?\n\nTo summarize, you\'ve expressed a desire for a job and used the phrase "pretty please," which suggests a polite and hopeful tone. If you have any specific job preferences or requirements, please let me know so I can assist you better.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55027]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 58 
total_tokens_used: 158 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're expressing a desire for a job in a playful manner. To better understand your request, could you please provide more details about the type of job you're interested in or any specific skills you have? This will help me assist you more effectively.\n\n**Summary of Your Request:**\n- You're asking for a job in a polite and humorous way.\n- You haven't specified a particular job type or industry.\n\nLet's discuss further to explore potential opportunities that might suit you", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55125]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 76 
prompt_tokens_used: 58 
total_tokens_used: 134 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? That way, I can better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'re using a playful tone by saying "give me a job pretty please." Let\'s have a more formal conversation about your job search. Could you tell me a bit about your background, skills, and what kind of job you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job and seem open to various opportunities. Is there a specific industry or role that interests you?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experience that might help narrow down some options?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 58 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You\'ve said, "Give me a job pretty please." Let\'s have a conversation about what you\'re looking for in a job and what skills or experiences you might have that could be relevant.\n\nCould you tell me a bit more about yourself? What kind of job are you interested in, and what skills or qualifications do you have?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 58 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner, saying "give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor. Could you tell me more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 109 
prompt_tokens_used: 58 
total_tokens_used: 167 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather creative way. You've expressed a desire for employment with a playful tone. Could you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you're interested in? This will help me better understand how I can assist you in your job search. \n\nTo summarize, you're looking for a job and have approached the request in a unique manner. Let's explore your qualifications and what kind of position might be a good fit for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 58 
total_tokens_used: 168 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you mentioned "Pretty Please," which might be related to a specific company or context. Could you clarify what kind of job you\'re interested in or what you mean by "Pretty Please"? This will help me better understand your request and provide a more accurate response.\n\n**Summary of Your Request:**\n- You asked for a job.\n- You mentioned "Pretty Please," which could be a company or a specific job context.\n- You did not specify the type of job you are interested in.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 109 
prompt_tokens_used: 58 
total_tokens_used: 167 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nTo summarize, you\'re expressing a desire for a job, and you\'re doing so in a polite and humorous manner. Could you tell me a bit more about the type of job you\'re interested in or what skills you bring to the table? This would help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about what kind of job you\'re interested in or what skills you have that could be relevant to a potential position.\n\nCould you tell me a bit more about your background, skills, or any specific job roles you\'re interested in? This will help us explore opportunities that might be a good fit for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55195]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 347 
prompt_tokens_used: 1218 
total_tokens_used: 1565 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're looking for job opportunities. Here are some in-demand jobs for 2025, along with a few tips on how to approach your job search:\n\n## In-Demand Jobs for 2025\n\n1. **Veterinarian**: With a median salary of $139,999 and a 124% increase in job postings, veterinarians are in high demand due to the growing pet industry[1].\n2. **Physician**: Physicians are among the highest-paid professionals, with a median salary of $225,000. The healthcare sector continues to grow due to an aging population[1].\n3. **Data Scientist**: Data scientists are crucial for analyzing business data, with a median wage of $51.93 per hour and a 9% job outlook increase[3].\n4. **Actuary**: Actuaries are needed to assess financial risks, especially in insurance, with a median wage of $57.69 per hour and a 9% job outlook increase[3].\n\n## Tips for Job Hunting\n\n- **Update Your Resume**: Ensure your resume highlights relevant skills and experiences.\n- **Network**: Use professional networks like LinkedIn to connect with potential employers.\n- **Upskill**: Consider acquiring skills in AI, big data, and cybersecurity, which are in high demand[5].\n- **Flexibility**: Be open to remote or hybrid work options, as many jobs now offer these arrangements[1].\n\nIf you're interested in a specific field or location, you might want to explore job boards or reach out to companies directly. For instance, if you're interested in aesthetics, you could send your resume to companies like Pretty Please Aesthetics, even if they're not currently hiring[4].", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'.wav\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 58 
total_tokens_used: 135 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re seeking a job and are open to suggestions or opportunities. Is there a specific field or type of job you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'.wav\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 116 
prompt_tokens_used: 58 
total_tokens_used: 174 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s break down what you\'re looking for:\n\n1. **Job Request**: You\'re seeking a job opportunity.\n2. **Tone**: You\'ve used a polite and friendly tone, which is great for engaging in a conversation.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'.wav\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous manner. Could you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'.wav\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 58 
total_tokens_used: 135 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand how I can assist you. \n\nTo summarize, you're looking for a job and would like some assistance in finding one. Is that correct?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'.wav\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55478]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo summarize, you\'re expressing interest in finding a job and are hoping for assistance or guidance in that process. Is there a specific type of job or industry you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': '[{\'type\': \'enum\', \'loc\': (\'body\', \'response_format\'), \'msg\': "Input should be \'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'", \'input\': \'WAV\', \'ctx\': {\'expected\': "\'mp3\', \'aac\', \'opus\', \'flac\', \'pcm\' or \'wav\'"}}]', 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55543]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 111 
prompt_tokens_used: 58 
total_tokens_used: 169 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re making a playful request for a job. Let\'s break it down:\n\n- **You said:** "Give me a job pretty please." This suggests you\'re looking for employment and are expressing your request in a polite and humorous way.\n  \n- **Summary:** You\'re seeking a job opportunity and are open to discussing potential roles or positions.\n\nNow, let\'s have a conversation about what kind of job you might be interested in. What are your skills or areas of interest? Are there any specific industries or roles you\'re considering?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a lighthearted manner.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about your job search. Could you tell me a bit about yourself, such as your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and friendly way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking for it in a polite manner. You said, "Give me a job pretty please." This indicates that you\'re interested in finding employment and are approaching the request with a positive and respectful attitude.\n\nTo summarize, you\'re looking for a job opportunity and are open to discussing potential roles or positions that might be available. Is there a specific type of job or industry you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Finished server process [55575]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, and what kind of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." Could you tell me a bit more about yourself and what kind of job you\'re interested in? What are your skills and qualifications? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job and are approaching the request in a friendly and polite way. Is there a specific industry or role you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly, polite way.\n\nTo summarize, you\'re interested in finding a job and are open to discussing potential opportunities. Is there a specific field or type of job you\'re interested in, or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you please tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specific details yet. Let's explore your preferences and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for assistance or guidance in finding a position.\n\nTo better assist you, could you tell me a bit about your background, skills, or the type of job you\'re interested in? This information will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 111 
prompt_tokens_used: 58 
total_tokens_used: 169 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for assistance in finding employment. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have? That way, I can offer more tailored advice or suggestions. \n\nTo summarize, you\'re seeking a job and would like some help in that process. Is there a specific industry or role you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 4096 
prompt_tokens_used: 58 
total_tokens_used: 4154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Ingredients, the, the,,,,,,,,,,,,,,,,,,,,,, the the, the the,,,, the,,,,,, the, the,,,,,, the the,,,, the the,,,,,,,,,,,, the,,,,, the,, the,, the,,, the,,,,,, the,,,, the,, the,,,,, the, the,, the the, the,,, the,,,, the, the,, the, the, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,, the, the, the,,,,,,, the,,,,,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,, the,,,,, the,,,,,,,,i,,,, the, the,,,,, the,,,,,, the,,,,,,, the, the,,,,,,,,,,,, the,, the,,, the, the, the,,,,,,,,,, the,,,, the,, the,,,, the,,,,,, the,,,,,,,,,,,,,,, the,, the,,,,, the,,,,,, the,,,,, the,,,,,,,,,,, the,,,,,,,,,,,,,,, the, the,,, the,,, the,,,,,,,,,,, the, the, the,,,,,,,,,, the,,,,,,,,,,, the,, the,,,,,,,,,, the,,,,,,,,,,, the,,, the,, the,,,,, the, the the the, the,,,,,,,, the the the,,,, the,, the, the,,,,,,,,,,,,,, the,,,,,, the the the,,,,,, the, the the,, the,, the, the, the, the the,, the,, the the,,, the, the,, the the,,,,,,, the, the,,,,,,,,,,,,,, the,,, the,,,,, the, the,, the, the,, the,, the,,,,,,, the,,,,,, the, the,,,,, the,,,, the,, the, the the,,,,,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,, the the,,,,, the,,,,,,,,,,,,,,,,,,,,,, the the,,,, the,, the the, the,,,,,, the, the,,,, the,,,, the,, the,, and the,,,,,,, the the,,,,,,, and,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,, the,,,, the, the,, the,, the,,, the, the,, the the, the,,,, the,,,,,,, the,,,,, the,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,, the,, the the,,,,, the,,, the,,,, the, the,,, and the,,,,,,, the,,,,,,,,,, the, the, the,,,, the,,,,,,,,,, the,,, the,,, the,, the,,,,,,,,, the,,,,, the,,,,,,,,,,,,, the, the, the,,, the, the, the,,, the,, the the,, the,, the, the,,,,,,,,, the,,,,,, the, the,,, Des,,,,,,, the and,, the, the, the, the, the,, the the,,, the the,,, and the,,,,,,,, the,, the,,, the the,, the,,,, the,,, the the, the,,, the,, the,,,,, the, the, the, the, the,,, the, the,,,,,,,,,, the,,,, the,,,,,,,, the the,, the, the, the the,, the,,, the, the the,,, the,,,, the the, the the,, the,,,, the, the,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,, the,,,,,,,,, the,,,,,, the,,,, the,, the the, the,, the the the the the,,,, the, the the,,,,,,,,,,,,,, the,,,,,,,,,,,,, and,,,,,, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,, and the,,,,,,, and,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the, the,,,, the,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,, the,,,,,,, the, the,,,,, the, the,, they, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,, the,, the,,,,, (,,,,,, and the,,,,,,, the, the,,,,, the,,,,,,,,, the,,, and,,,,,,, the,, the,,,,, the, (,,,, the, the,,,,, and,,,, and,,,,, the,,,, the,,,,,,, the,,,,, the, the,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,, the,,, the,,, the,,, the,,, the,,,, the,,,,,,,, the,,,, the,,,,, the, the the, (,,, a,,,,,, ( the,, the,,,, and,,,,,,,,, the,, the, the,,,,,,,,,,,,,,,,,, and,, the, the, the,,,,,,,,,, the,,,,,,,,,,,,,,,, the,,,,,,,,, and,,,,, the,,,,,,, the,,,, the the, the the,, the,,,,,,,, the,, and,,,,,,, and,, and,,,,,,, the,,,,,,, and,, and,,,,,,,,,,, the,,,,, the, the the the, the,, the,,, the,,, and, the,,,,,,, the,,,, the, the,,,,,,,,,,,, and (,,,,,,,,,,,,,,,,,,, the,, the the,,, the, the,,, the, the the, the the the the the, the the,, the, the,, the,, the the the the, the,, the,,,, and, the,,,,,, the the,,, and, the,,,,,,,, the,,,,,, the,,,,,,,,,, and,,,, the,,, the, the, the,, the the,,,,,,,,,, the, the,,, the, and,,, the,,,,,,,,, the,,, the, the,, the the,,, the and the,,,, and, the, the the,,,,,,, the,, the the, the,, the the,,, the the,,, and the, the,,,,, and,,,, the,,, the,,,,,,,,,,,,, the, the, the, the, the,,,,,,, the,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,, the,,,,,,,, the,,,,,,,,,,,,,, and the,,,,,,,,,, the,, the and,,,,,,,,,,,,,,,,,,,,,,, the,, and,,,,,,,,,,, the,,,,,,,, the the a, the,,,,,,, the,,,, the,,, the the the, the,,,,,,,,,,, the,,,,,,,,, the the, the,,, the,,,, and, the, the, the, the,,,,,, the,, the,, the,, the, the, the, and,,,,,,,, the, the, and the, the the,, the,,, the,,, the,,,, and the,, the, the the and and, the,,, and,,,,,, the,,, and the,,,,,,,,,,,,,,,,, and,,,, the,,, and the, the,, and,,,,,,,,, the,,, the,,,,,,,, the, the,, the,,,, the, and, the,,, and,,,,,,,,,,,,,,,, the,, the,,,,,,,,,, the,,, the, the and the, and the, the the,,,, the, and,, the,,,,,, the, the,,,,,,,,, and,,,,, and,, the,,,,,,,,,,,,, and,,,,,,,,,,,,,, the, the,,, the and the, the the,, the, the,,, and,,,,, the, the,, the,,, the,,,,,,, the, the the,,, (,, the,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and, the,, the, the and,,, the, the the, the,,,,,,,,,,,,, the, (,, the,,,,,, the,,,,,,,,,,,, and,,,,,, the,,,,, the the the,,,,,,,,,,,,, and the,, and,,, the, the,, the,,,,, the,, the,,,,,,,, the, the, the, the, and the,,,, the the,,,,,,,,,,, the, the,,,,,,,,, the, the,,,,, the,, the,,,,,,,,,,,,,, the,,,,, the,,,,, the, the, and,,,,,,,,, and, the,,,,,,,,,,,,, the,,, the,,,,,, the,,, the,,,,,,,,,, the, the,, the,,,,,,,,,, the,,,,,,,,,, the,,,,,,,,,,,,, the,,,,,, the,, and, the,,,,,,,,, the,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,, the,,,,,, and,,,,,, the, the,,,,,,,,,,,,,,, the the,,', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 400 Bad Request"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 46, in generate_conversation
    questionAudioURL = audioGen.generateAudio(questionText['text'])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 20, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "[{'type': 'string_too_long', 'loc': ('body', 'input'), 'msg': 'String should have at most 4096 characters', 'input': 'Ingredients, the, the,,,,,,,,,,,,,,,,,,,,,, the the, the the,,,, the,,,,,, the, the,,,,,, the the,,,, the the,,,,,,,,,,,, the,,,,, the,, the,, the,,, the,,,,,, the,,,, the,, the,,,,, the, the,, the the, the,,, the,,,, the, the,, the, the, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,, the, the, the,,,,,,, the,,,,,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,, the,,,,, the,,,,,,,,i,,,, the, the,,,,, the,,,,,, the,,,,,,, the, the,,,,,,,,,,,, the,, the,,, the, the, the,,,,,,,,,, the,,,, the,, the,,,, the,,,,,, the,,,,,,,,,,,,,,, the,, the,,,,, the,,,,,, the,,,,, the,,,,,,,,,,, the,,,,,,,,,,,,,,, the, the,,, the,,, the,,,,,,,,,,, the, the, the,,,,,,,,,, the,,,,,,,,,,, the,, the,,,,,,,,,, the,,,,,,,,,,, the,,, the,, the,,,,, the, the the the, the,,,,,,,, the the the,,,, the,, the, the,,,,,,,,,,,,,, the,,,,,, the the the,,,,,, the, the the,, the,, the, the, the, the the,, the,, the the,,, the, the,, the the,,,,,,, the, the,,,,,,,,,,,,,, the,,, the,,,,, the, the,, the, the,, the,, the,,,,,,, the,,,,,, the, the,,,,, the,,,, the,, the, the the,,,,,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,, the the,,,,, the,,,,,,,,,,,,,,,,,,,,,, the the,,,, the,, the the, the,,,,,, the, the,,,, the,,,, the,, the,, and the,,,,,,, the the,,,,,,, and,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,, the,,,, the, the,, the,, the,,, the, the,, the the, the,,,, the,,,,,,, the,,,,, the,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,, the,, the the,,,,, the,,, the,,,, the, the,,, and the,,,,,,, the,,,,,,,,,, the, the, the,,,, the,,,,,,,,,, the,,, the,,, the,, the,,,,,,,,, the,,,,, the,,,,,,,,,,,,, the, the, the,,, the, the, the,,, the,, the the,, the,, the, the,,,,,,,,, the,,,,,, the, the,,, Des,,,,,,, the and,, the, the, the, the, the,, the the,,, the the,,, and the,,,,,,,, the,, the,,, the the,, the,,,, the,,, the the, the,,, the,, the,,,,, the, the, the, the, the,,, the, the,,,,,,,,,, the,,,, the,,,,,,,, the the,, the, the, the the,, the,,, the, the the,,, the,,,, the the, the the,, the,,,, the, the,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,, the,,,,,,,,, the,,,,,, the,,,, the,, the the, the,, the the the the the,,,, the, the the,,,,,,,,,,,,,, the,,,,,,,,,,,,, and,,,,,, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,, and the,,,,,,, and,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the, the,,,, the,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,, the,,,,,,, the, the,,,,, the, the,, they, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,, the,, the,,,,, (,,,,,, and the,,,,,,, the, the,,,,, the,,,,,,,,, the,,, and,,,,,,, the,, the,,,,, the, (,,,, the, the,,,,, and,,,, and,,,,, the,,,, the,,,,,,, the,,,,, the, the,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,, the,,, the,,, the,,, the,,, the,,,, the,,,,,,,, the,,,, the,,,,, the, the the, (,,, a,,,,,, ( the,, the,,,, and,,,,,,,,, the,, the, the,,,,,,,,,,,,,,,,,, and,, the, the, the,,,,,,,,,, the,,,,,,,,,,,,,,,, the,,,,,,,,, and,,,,, the,,,,,,, the,,,, the the, the the,, the,,,,,,,, the,, and,,,,,,, and,, and,,,,,,, the,,,,,,, and,, and,,,,,,,,,,, the,,,,, the, the the the, the,, the,,, the,,, and, the,,,,,,, the,,,, the, the,,,,,,,,,,,, and (,,,,,,,,,,,,,,,,,,, the,, the the,,, the, the,,, the, the the, the the the the the, the the,, the, the,, the,, the the the the, the,, the,,,, and, the,,,,,, the the,,, and, the,,,,,,,, the,,,,,, the,,,,,,,,,, and,,,, the,,, the, the, the,, the the,,,,,,,,,, the, the,,, the, and,,, the,,,,,,,,, the,,, the, the,, the the,,, the and the,,,, and, the, the the,,,,,,, the,, the the, the,, the the,,, the the,,, and the, the,,,,, and,,,, the,,, the,,,,,,,,,,,,, the, the, the, the, the,,,,,,, the,,,,,, the,, the,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and,,,,,,, the,,,,,,,, the,,,,,,,,,,,,,, and the,,,,,,,,,, the,, the and,,,,,,,,,,,,,,,,,,,,,,, the,, and,,,,,,,,,,, the,,,,,,,, the the a, the,,,,,,, the,,,, the,,, the the the, the,,,,,,,,,,, the,,,,,,,,, the the, the,,, the,,,, and, the, the, the, the,,,,,, the,, the,, the,, the, the, the, and,,,,,,,, the, the, and the, the the,, the,,, the,,, the,,,, and the,, the, the the and and, the,,, and,,,,,, the,,, and the,,,,,,,,,,,,,,,,, and,,,, the,,, and the, the,, and,,,,,,,,, the,,, the,,,,,,,, the, the,, the,,,, the, and, the,,, and,,,,,,,,,,,,,,,, the,, the,,,,,,,,,, the,,, the, the and the, and the, the the,,,, the, and,, the,,,,,, the, the,,,,,,,,, and,,,,, and,, the,,,,,,,,,,,,, and,,,,,,,,,,,,,, the, the,,, the and the, the the,, the, the,,, and,,,,, the, the,, the,,, the,,,,,,, the, the the,,, (,, the,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,,,,,,, and, the,, the, the and,,, the, the the, the,,,,,,,,,,,,, the, (,, the,,,,,, the,,,,,,,,,,,, and,,,,,, the,,,,, the the the,,,,,,,,,,,,, and the,, and,,, the, the,, the,,,,, the,, the,,,,,,,, the, the, the, the, and the,,,, the the,,,,,,,,,,, the, the,,,,,,,,, the, the,,,,, the,, the,,,,,,,,,,,,,, the,,,,, the,,,,, the, the, and,,,,,,,,, and, the,,,,,,,,,,,,, the,,, the,,,,,, the,,, the,,,,,,,,,, the, the,, the,,,,,,,,,, the,,,,,,,,,, the,,,,,,,,,,,,, the,,,,,, the,, and, the,,,,,,,,, the,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,, the,,,,,, and,,,,,, the, the,,,,,,,,,,,,,,, the the,,', 'ctx': {'max_length': 4096}}]", 'type': 'invalid_request_error', 'param': None, 'code': None}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 159 
prompt_tokens_used: 1218 
total_tokens_used: 1377 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job at **Pretty Please Aesthetics**. However, according to their website, they are not currently hiring for any positions. They do encourage interested individuals to send their resumes for future consideration[4].\n\nIf you're interested in careers related to aesthetics or healthcare, here are some in-demand jobs for 2025:\n\n- **Clinical Psychologist**: Median salary around $118,597, with a significant increase in job postings[1].\n- **Registered Nurse**: Median salary about $125,531, with a high demand due to an aging population[1].\n- **Data Scientist**: Median wage around $51.93 per hour, with a growing need across industries[3].\n\nThese roles require specialized education and training but offer promising career paths.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and hopeful way.\n\nCould you tell me a bit more about what kind of job you\'re interested in or what skills you have? This will help me better understand your needs and provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and hopeful way.\n\nTo better assist you, could you tell me a bit about your skills, interests, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Let's have a conversation about your job interests and qualifications. Could you tell me a bit about yourself, such as your background, skills, and what kind of job you're looking for? This will help me better understand how I can assist you. \n\nTo summarize, you're expressing a desire for a job opportunity, and I'd like to explore your qualifications and interests further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 115 
prompt_tokens_used: 58 
total_tokens_used: 173 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break it down:\n\n1. **Job Request**: You\'re looking for a job opportunity.\n2. **Polite Approach**: You\'ve used "pretty please," which indicates a polite and respectful tone in your request.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 117 
prompt_tokens_used: 58 
total_tokens_used: 175 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job, pretty please." This suggests you\'re interested in exploring potential job opportunities. Could you tell me a bit more about what kind of job you\'re looking for or what skills you have that might be relevant? This will help me better understand your needs and provide more tailored advice. \n\nTo summarize, you\'re expressing interest in finding a job and are asking for assistance in a lighthearted way. Is there a specific industry or role you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Let's break it down:\n\n1. **Your Request**: You've expressed a desire for a job, using a polite and humorous tone.\n   \n2. **Summary**: You're looking for employment opportunities and are open to suggestions or assistance in finding a suitable position.\n\nNow, let's discuss how we can help you with your job search. What type of job are you interested in? Do you have any specific skills or industries in mind?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job, pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a lighthearted manner.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [55681]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand your needs and provide more tailored advice or opportunities. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." This suggests you\'re looking for employment opportunities and are perhaps feeling a bit challenged in your job search.\n\nTo summarize, you\'re seeking assistance or guidance in finding a job. Is there a specific field or type of job you\'re interested in? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [56172]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you please elaborate on what kind of job you're interested in or what skills you have that might be relevant to a position? This will help me better understand your request and provide more tailored advice or opportunities. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." This suggests you\'re interested in exploring potential job opportunities. Could you tell me a bit more about what kind of job you\'re looking for or what skills you have that might be relevant to a position? This will help me better understand how I can assist you. \n\nTo summarize, you\'re seeking employment and are open to discussing potential roles. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 58 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are open to exploring different roles. Could you tell me a bit more about your interests, skills, or any specific job types you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor. Could you tell me more about the type of job you\'re interested in or what skills you have that might be relevant to a position? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 58 
total_tokens_used: 137 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor. Could you tell me more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nLet\'s discuss your job interests and qualifications. What type of job are you looking for? Do you have any specific skills or experiences that you think would be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job opportunity in a somewhat playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous manner.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have to offer? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 76 
prompt_tokens_used: 58 
total_tokens_used: 134 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous manner. Could you tell me a bit more about the type of job you\'re interested in or what skills you have that might be relevant to a position?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 121 
prompt_tokens_used: 58 
total_tokens_used: 179 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You said, "g i v e   m e   a   j o b   p r e t t y   p l e a s e." This suggests you\'re looking for assistance in finding employment. Let\'s discuss your interests and qualifications to see how I can best support you in your job search.\n\nCould you tell me a bit about your background, skills, or any specific areas you\'re interested in? This will help me provide more tailored advice or suggestions for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 121 
prompt_tokens_used: 58 
total_tokens_used: 179 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break down what you\'ve said:\n\n1. **Requestassistant\n2. **Tone**: You\'ve used a polite and somewhat informal tone by adding "pretty please," which suggests a friendly and hopeful approach.\n\nNow, let\'s have a conversation about your job search. Could you tell me a bit more about what kind of job you\'re looking for? What are your interests or skills that might align with a particular role?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 119 
prompt_tokens_used: 58 
total_tokens_used: 177 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Interviewer: Hi there It seems like you\'re looking for a job. Could you tell me a bit more about what you\'re interested in or what kind of job you\'re hoping to find? \n\n---\n\n**Summary of Your Request:**\n- You\'re asking for a job, using the phrase "give me a job pretty please."\n- There\'s no specific job type or industry mentioned.\n- You might be open to various opportunities based on your interests or skills. \n\nLet\'s explore some options together What are your skills or interests that might help narrow down some job possibilities?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seemsassistant\n\nIt seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and polite way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This would help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Could you tell me a bit more about what kind of job you're interested in? What skills or experiences do you have that might be relevant to a position you're looking for? Let's have a conversation about your career aspirations and see how I can assist you. \n\nTo summarize, you're expressing a desire for a job opportunity and are open to discussing your qualifications and interests. Is that correct?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 204 No Content"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 35, in generate_conversation
    questionText = textGen.generateText(
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 62, in generateText
    f"completion_tokens_used: {response.usage.completion_tokens} \n"
                               ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'usage'
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 524 "
INFO:openai._base_client:Retrying request to /chat/completions in 0.396402 seconds
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 58 
total_tokens_used: 172 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='\n\nYou\'ve expressed a desire for a job, saying "give me a job pretty please." It seems like you\'re looking for employment opportunities. Can you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you\'re interested in? This will help me better understand how to assist you. \n\nAlso, are youassistant}\nopen to exploring different sectors, or do you have a particular industry in mind?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It sounds like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re eager to find employment and are reaching out for assistance or guidance in your job search.\n\nCould you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant to potential employers? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request in a lighthearted manner. Could you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You\'ve said, "Give me a job pretty please." This suggests that you\'re looking for employment and are approaching the request in a lighthearted manner.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 58 
total_tokens_used: 139 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor. Could you tell me a bit more about yourself, such as your skills or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in a friendly manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for some guidance or assistance in finding a suitable position.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 68 
prompt_tokens_used: 58 
total_tokens_used: 126 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." Let\'s explore this further. Could you tell me a bit about your background, skills, or any specific job roles you\'re interested in? This will help us have a more focused conversation about potential job opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 63 
prompt_tokens_used: 58 
total_tokens_used: 121 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're expressing a playful request for a job. To summarize, you're asking for a job opportunity in a lighthearted manner. Let's explore this further. What kind of job are you interested in, and what skills or experiences do you have that might align with available positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking in a polite manner. You\'re essentially saying, "Please give me a job." Could you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for employment opportunities and are open to discussing your qualifications and preferences. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire for a job, and I\'m here to help facilitate that conversation. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo summarize, you\'re expressing interest in finding a job and are open to discussing potential opportunities. Is there a specific field or type of job you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 144 
prompt_tokens_used: 58 
total_tokens_used: 202 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re interested in exploring potential job opportunities. Could you tell me a bit more about what kind of job you\'re looking for or what skills you have that might be relevant? This will help me better understand your needs and provide more tailored advice. \n\nAlso, I noticed that Pretty Please Aesthetics is not currently hiring, but they do appreciate receiving resumes for future opportunities[4]. If you have experience in aesthetics or related fields, that might be worth exploring further. \n\nLet\'s discuss your interests and qualifications to see how we can assist you in finding the right fit.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 58 
total_tokens_used: 139 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. Let me summarize what you\'ve said: You\'re looking for a job opportunity and are expressing your interest in a polite manner.\n\nTo continue our conversation, could you tell me a bit more about the type of job you\'re interested in? Are there any specific industries or roles you\'re considering?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 107 
prompt_tokens_used: 58 
total_tokens_used: 165 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch to your request by saying "pretty please." Let\'s have a conversation about what kind of job you might be interested in or what skills you have to offer. Could you tell me a bit more about your background, skills, or any specific job roles that interest you? This will help us explore potential opportunities together. \n\nTo summarize, you\'ve expressed a desire for a job and are open to discussing your qualifications and interests. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 141 
prompt_tokens_used: 58 
total_tokens_used: 199 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in a mock interview setting. Let\'s break down what you\'ve said:\n\n- You\'re interested in obtaining a job.\n- You\'ve mentioned "pretty please," which might refer to a specific company or a polite way of asking for a job.\n\nTo proceed, could you please clarify what type of job you\'re interested in or if you have a specific role in mind at a company like Pretty Please Boutique? This will help us tailor the conversation to your needs. \n\nAlso, if you have any relevant skills or experiences you\'d like to highlight, feel free to share them. Let\'s have a productive conversation', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." This could be a lighthearted way of asking for assistance in finding employment. You might be looking for guidance or resources to help you navigate the job market.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 58 
total_tokens_used: 172 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s break down what you might be looking for:\n\n1. **Job Request**: You\'re expressing a desire for employment.\n2. **Tone**: The "pretty please" suggests a lighthearted or humorous approach.\n\nTo help you further, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 76 
prompt_tokens_used: 58 
total_tokens_used: 134 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. To summarize, you\'re expressing a polite and enthusiastic interest in obtaining a job. Could you tell me a bit more about the type of job you\'re interested in or what skills you bring to the table? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 58 
total_tokens_used: 158 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Let's have a conversation about your job interests and qualifications. Could you tell me a bit about yourself, such as your educational background, any relevant work experience, and what type of job you're interested in? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specifics yet. Let's explore your interests and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you please tell me a bit more about yourself and what kind of job you're interested in? What are your skills and qualifications? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specifics yet. Let's explore your interests and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response\n\nLet\'s have a conversation about your job search. Could you tell me a bit about your background, skills, and what kind of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This would help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break it down:\n\n- **Your Request**: You\'re looking for a job opportunity.\n- **Tone**: You\'ve added a polite and friendly tone with "pretty please."\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response.\n\nTo summarize, you\'re seeking a job and are approaching the request in a polite and hopeful manner. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This would help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and hopeful manner.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Could you tell me a bit more about your skills, interests, or any specific job roles you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted manner.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor and politeness.\n\nTo summarize, you\'re expressing interest in finding a job and are hoping for assistance in doing so. Is there a specific type of job or industry you\'re interested in? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to assist you in finding one. You\'ve said, "Give me a job pretty please." This indicates that you\'re eager to secure employment and are hoping for some guidance or assistance in your job search.\n\nTo better understand your needs and preferences, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experiences that might help narrow down some options?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'re being quite polite about it. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a friendly manner.\n\nTo summarize, you\'re expressing a desire to find a job and are open to any opportunities that might be available. Is there a specific type of job or industry you\'re interested in? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 111 
prompt_tokens_used: 58 
total_tokens_used: 169 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." Let\'s break down what you\'ve communicated:\n\n1. **Request for a Job**: You\'re expressing a desire to be employed.\n2. **Polite Tone**: The use of "pretty please" indicates a polite and respectful approach to your request.\n\nTo further assist you, could you tell me a bit more about your skills, interests, or any specific job roles you\'re interested in? This will help tailor our conversation to your needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 109 
prompt_tokens_used: 58 
total_tokens_used: 167 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and I\'m here to help facilitate a conversation about that. You\'ve said, "Give me a job pretty please." Let\'s break down what you\'re looking for:\n\n1. **Job Interest**: You\'re interested in finding a job.\n2. **Tone**: Your request is polite and hopeful.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experiences that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 111 
prompt_tokens_used: 58 
total_tokens_used: 169 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'ve included the phrase "pretty please." Let\'s break it down:\n\n1. **Job Request**: You\'re asking for a job opportunity.\n2. **"Pretty Please"**: This is a polite and somewhat playful way to make a request.\n\nTo summarize, you\'re asking for a job in a friendly and hopeful manner. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have? This will help me better understand your request.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 71 
prompt_tokens_used: 58 
total_tokens_used: 129 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor. Could you tell me a bit more about yourself and what kind of job you\'re interested in? What are your skills and experiences?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests that you\'re looking for employment and are hoping for a favorable response.\n\nTo better understand your needs, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or guidance.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 58 
total_tokens_used: 135 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor and politeness.\n\nLet\'s explore this further. What kind of job are you interested in? Are there any specific industries or roles you\'ve been considering?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire to find a job, and you\'re doing so in a lighthearted way. Could you tell me a bit more about the type of job you\'re interested in or what skills you have that might be relevant to a potential employer?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 75 
prompt_tokens_used: 58 
total_tokens_used: 133 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." Let me summarize what you\'ve expressed: You\'re seeking employment and are making a polite request for a job opportunity. Is there a specific type of job or industry you\'re interested in? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 58 
total_tokens_used: 131 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." This suggests you\'re looking for employment opportunities and are eager to find a position. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous way.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about what you\'re looking for in a job. Could you tell me a bit about your background, skills, and what kind of job you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job opportunity and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 58 
total_tokens_used: 168 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You said, "Give me a job pretty please." This indicates that you\'re looking for assistance in finding employment. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? That way, I can better understand how to assist you. \n\nTo summarize, you\'re seeking help in obtaining a job, and you\'re open to guidance on how to proceed. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and polite way.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to assist you in finding one. You\'ve said, "Give me a job pretty please." This suggests that you\'re eager to start working and are looking for help in securing employment.\n\nCould you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that could be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Could you tell me a bit more about what kind of job you're interested in or what skills you have? That way, I can better understand how to assist you.\n\n**Summary of Your Request:**\n- You're asking for a job in a polite and humorous way.\n- You haven't specified a particular job type or industry yet.\n\nLet's discuss your interests and qualifications to explore potential job opportunities", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 58 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nTo summarize, you\'re expressing a desire to find a job, and you\'re doing so in a polite and humorous manner. Could you tell me a bit more about your skills or the type of job you\'re interested in? This would help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re interested in finding employment and are approaching the request in a lighthearted manner.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you looking for, and what skills or experiences do you have that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are expressing your request in a polite and humorous way. Could you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor and politeness. Could you tell me a bit more about yourself, such as your skills or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 173 
prompt_tokens_used: 1218 
total_tokens_used: 1391 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job at "Pretty Please Aesthetics." However, according to their website, they are not currently hiring for any positions. You can still express your interest by sending your resume to them for future consideration[4].\n\nIf you\'re interested in jobs related to aesthetics or healthcare, here are some in-demand roles for 2025:\n\n- **Clinical Psychologist**: Median annual salary of $118,597, with a 75% increase in job postings over the past three years[1].\n- **Registered Nurse**: Median annual salary of $125,531, with a 146% increase in job postings[1].\n\nFor more general in-demand jobs in 2025, consider roles like **Data Scientist**, **Actuary**, and **Accountant**, which are expected to see growth in the coming years[3].', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 58 
total_tokens_used: 158 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said, "Give me a job pretty please." Let\'s break down what you\'re looking for:\n\n- **Job Request**: You\'re seeking employment.\n- **Polite Approach**: You\'re using a polite and friendly tone to make your request.\n\nTo assist you further, could you please provide more details about the type of job you\'re interested in or any specific skills you have? This will help tailor the conversation to your needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in? What are your skills or areas of interest? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a very polite manner. You\'ve expressed a desire for employment, using the phrase "give me a job pretty please." This indicates that you\'re eager to find work and are approaching the situation with a positive and respectful attitude.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted manner.\n\nTo summarize, you\'re expressing a desire for a job and are open to exploring available positions. Is there a specific field or type of job you\'re interested in, or would you like some general advice on where to start looking?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 80 
prompt_tokens_used: 58 
total_tokens_used: 138 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said: You\'re expressing a polite and enthusiastic request for a job opportunity. Could you tell me a bit more about the type of job you\'re interested in or what skills you bring to the table? This will help me better understand your request and guide our conversation.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'re expressing it in a polite manner. You said, "Give me a job pretty please." This indicates that you\'re interested in finding employment and are approaching the request with a friendly and humble tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." You\'re expressing a polite and enthusiastic interest in obtaining employment. Could you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job and are eager to explore opportunities. Is there a specific industry or role that interests you?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 315 
prompt_tokens_used: 1218 
total_tokens_used: 1533 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for job opportunities. Here are some in-demand jobs for 2025, along with some specific job listings:\n\n## In-Demand Jobs for 2025\n\n1. **Veterinarian**  \n   - Median Salary: $139,999  \n   - Job Outlook: 19% growth over the next nine years[1].\n\n2. **Physician**  \n   - Median Salary: $225,000  \n   - Job Outlook: High demand due to an aging population[1].\n\n3. **Data Scientist**  \n   - Median Wage: $51.93 per hour  \n   - Job Outlook: 9% increase from 2025 to 2033[3].\n\n4. **Actuary**  \n   - Median Wage: $57.69 per hour  \n   - Job Outlook: 9% increase from 2025 to 2033[3].\n\n5. **Barista**  \n   - Median Wage: $14.20 per hour  \n   - Job Outlook: 6 to 8% increase[3].\n\n## Specific Job Listings\n\n- **Pretty Please Boutique Jobs**: There are numerous retail and service jobs available, such as retail sales associates and floral designers[4].\n- **Hair Stylist/Assistant Manager**: Positions available at salons like Great Clips[4].\n- **Makeup Artist**: Opportunities for talented makeup artists in dynamic teams[4].\n\nThese jobs span various sectors, from healthcare and technology to retail and service industries. You can explore these options based on your skills and interests.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a polite manner. You've expressed a desire for employment, and I'd like to explore this further with you. Could you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you're interested in? This will help me better understand how I can assist you in your job search.\n\nTo summarize, you've asked for a job in a polite and courteous way, indicating that you're ready to engage in a conversation about potential employment opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about your job aspirations. Could you tell me a bit more about what kind of job you\'re interested in? What are your skills or areas of interest? \n\nTo summarize, you\'re looking for a job and are open to discussing your qualifications and preferences. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and I\'m here to help facilitate that conversation. You\'ve said, "Give me a job pretty please," which indicates you\'re looking for employment opportunities. Let\'s explore what kind of job you might be interested in and what skills you have to offer.\n\nCould you tell me a bit more about yourself? What kind of work are you interested in, and what skills or experiences do you have that could be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way, saying "give me a job pretty please." If I understand correctly, you\'re expressing a desire for employment assistance or perhaps a job opportunity. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This would help me better understand how I can assist you. \n\nTo summarize, you\'re seeking a job and would like some help or guidance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a playful manner, saying "give me a job pretty please." Let\'s have a conversation about what you\'re looking for in a job. Could you tell me a bit more about your interests, skills, or any specific roles you\'re interested in? This will help me better understand what kind of job might be a good fit for you.\n\nTo summarize, you\'re expressing a desire for employment and are open to discussing potential opportunities. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing interest in finding a job and are open to suggestions or opportunities. Is there a specific field or type of job you\'re interested in, or would you like some general advice on where to start looking?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 58 
total_tokens_used: 135 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." You\'re likely looking for employment opportunities and are hoping for assistance or guidance in finding a suitable position. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a playful manner. Could you please elaborate on what kind of job you're interested in or what skills you have? This will help me better understand your request and provide more relevant information or assistance.\n\nTo summarize, you've expressed a desire for a job, but haven't specified the type of job or your qualifications. If you could provide more details, I'd be happy to help", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 259 
prompt_tokens_used: 58 
total_tokens_used: 317 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in a polite manner. You\'ve mentioned "Pretty Please," which could refer to a company or a specific job request. Could you clarify what kind of job you\'re interested in or if there\'s a specific role at a company named "Pretty Please" that you\'re looking for?assistant\n\nTo summarize, you\'re seeking a job and have mentioned "Pretty Please," which might be related to a company or a specific job title. You haven\'t specified the type of job you\'re interested in, but it seems like you\'re open to exploring opportunities. If you could provide more details about the kind of role you\'re looking for, I\'d be happy to help further. \n\nHere are some general job categories that might be of interest:\n\n- **Beauty & Wellness**: If "Pretty Please" is related to this industry, roles might include sales associates, client care coordinators, or other positions within beauty services.\n- **General Job Search**: If you\'re open to various sectors, we can discuss in-demand jobs for 2025, such as those in healthcare, engineering, or technology.\n\nLet me know how I can assist you further', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 58 
total_tokens_used: 131 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor. Could you tell me more about the type of job you\'re interested in or what skills you have that might be relevant to a position?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 58 
total_tokens_used: 172 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break down what you\'ve said:\n\n1. **Job Request**: You\'re looking for a job.\n2. **Polite Tone**: You\'ve used "pretty please," which indicates a polite and hopeful tone.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help me better understand your needs and provide more tailored advice or opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in or if you have any specific qualifications? I\'d be happy to help you explore opportunities.\n\nTo summarize, you\'ve expressed a desire for a job, but we haven\'t discussed any specific details yet. Let\'s start by exploring what you\'re looking for in a role. Are you interested in a particular industry or type of work?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities. Could you tell me a bit more about yourself, such as your skills or the type of job you\'re interested in? This will help me better understand how to assist you. \n\nTo summarize, you\'re seeking a job and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire for a job, and I\'m here to help facilitate that conversation. Let\'s discuss what kind of job you\'re interested in or what skills you have that could be relevant to potential employers. What specific areas or industries are you interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 58 
total_tokens_used: 140 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This indicates that you\'re interested in finding employment and are approaching the request with a friendly and respectful tone.\n\nCan you tell me a bit more about yourself? What kind of job are you looking for, and what skills or experiences do you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you tell me a bit more about what you're looking for in a job? What kind of role or industry are you interested in? This will help me better understand your needs and provide more tailored advice or opportunities.\n\nTo summarize, you're asking for assistance in finding a job, but you haven't specified any particular job type or field yet. Is there anything specific you'd like to explore further?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said: You\'re expressing a polite and enthusiastic request for a job opportunity. Could you tell me a bit more about the type of job you\'re interested in or what skills you have that might be relevant to a position? This will help us have a more focused conversation about potential opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and I\'m here to help facilitate that conversation. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for assistance in finding a suitable position.\n\nTo better understand your needs, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 58 
total_tokens_used: 135 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are approaching the request with a bit of humor. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a potential employer?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for assistance in finding a position.\n\nTo better understand your needs, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a somewhat playful manner. Could you please tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand how to assist you. \n\nTo summarize, you've expressed a desire for a job, but haven't specified the type of job or industry you're interested in. Could you provide more details?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch to your request by saying "pretty please." Let\'s have a conversation about what kind of job you\'re interested in and what skills or experiences you bring to the table.\n\nCould you tell me a bit more about yourself? What type of job are you looking for, and what skills or qualifications do you have? This will help me better understand how I can assist you in your job search.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. To better assist you, could you please tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me provide you with more tailored advice or opportunities. \n\n**Summary of Your Request:**\n- You are asking for a job in a polite and humorous way.\n- You haven't specified a particular job type or industry yet.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 58 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous way.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please" in a playful manner. To summarize, you\'re expressing interest in obtaining a job position, possibly in a polite or humorous way. Could you tell me more about the type of job you\'re interested in or what skills you bring to the table? This will help me better understand your career aspirations and guide our conversation.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you tell me a bit more about what you're looking for in a job? What are your skills, interests, or any specific roles you're considering? This will help me better understand your needs and provide more tailored advice or suggestions. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specific details yet. Let's explore your qualifications and preferences further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 308 
prompt_tokens_used: 1218 
total_tokens_used: 1526 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Here are some job opportunities and trends that might interest you:\n\n## In-Demand Jobs for 2025\n\n1. **Veterinarian**: With a median annual salary of $139,999, veterinarians are in high demand due to the increasing pet ownership and the need for animal care[1].\n2. **Sales Representative**: Offers a median annual salary of $182,487 and involves promoting and selling products[1].\n3. **Physician**: A highly lucrative role with a median annual salary of $225,000, reflecting the ongoing need for healthcare professionals[1].\n4. **Data Scientist**: With a median wage of $51.93 per hour, data scientists are crucial for analyzing business data and making informed decisions[3].\n5. **Actuary**: Involves assessing financial risks, with a median wage of $57.69 per hour and a growing demand due to changing global risks[3].\n\n## Job Search Tips\n\n- **Networking**: Engage with professional networks like LinkedIn or forums to connect with potential employers[2].\n- **Skill Development**: Focus on acquiring skills in high-demand fields such as technology, healthcare, and engineering[1][3].\n- **Flexibility**: Consider remote or hybrid roles for better work-life balance[1].\n\n## Pretty Please Boutique Jobs\n\nIf you're interested in retail or related fields, there are various jobs available at boutiques, including sales associates and designers[4]. \n\nFor more specific job opportunities, you can explore platforms like Indeed or local job boards.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 321 
prompt_tokens_used: 1218 
total_tokens_used: 1539 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here are some job opportunities and in-demand roles for 2025:\n\n## In-Demand Jobs for 2025\n\n1. **Veterinarian**: With a median salary of $139,999, veterinarians are in high demand due to an increase in pet ownership and a projected growth rate much faster than average[1].\n2. **Sales Representative**: Offers a median salary of $182,487, with significant job postings and growth[1].\n3. **Physician**: Median salary is $225,000, with sustained demand due to an aging population[1].\n4. **Data Scientist**: Median wage of $51.93 per hour, with a 9% increase in job outlook from 2025 to 2033[3].\n5. **Actuary**: Median wage of $57.69 per hour, with a 9% increase in job outlook due to increasing risk assessments[3].\n\n## Job Openings\n\n- **Pretty Please Boutique Jobs**: Various retail and design positions are available, including sales associates and designers[4].\n- **Technical and Engineering Roles**: Positions like usability testing and user interface design are in demand, especially with experience in human factors and ergonomics[2].\n\n## Tips for Job Hunting\n\n- **Networking**: Utilize online forums and professional networks to seek assistance and advice from experienced individuals[2].\n- **Skill Development**: Focus on developing skills in high-demand fields such as healthcare, engineering, and data science[1][3].\n- **Flexibility**: Consider roles with remote or hybrid options for better work-life balance[1].', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job opportunity in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nTo help you further, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a somewhat playful manner. Could you please elaborate on what kind of job you're interested in or what skills you have that might be relevant to a position? This will help me better understand your request and provide more tailored advice.\n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 58 
total_tokens_used: 168 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nTo summarize, you\'re expressing a desire for a job, and I\'m here to help facilitate that conversation. Could you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." You\'re likely looking for assistance or guidance in finding employment. Can you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re seeking a job and would appreciate any help or advice in that area. Is there anything specific you\'d like to focus on, such as a particular industry or role?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 58 
total_tokens_used: 172 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a bit of a playful tone with "pretty please." Let\'s start with a more formal approach. Could you tell me a bit about yourself, your skills, and what kind of job you\'re interested in? This will help me understand how I can assist you better.\n\n**Summary of Your Request:**\n- You\'re looking for a job.\n- You\'ve added a playful tone to your request.\n\nLet\'s discuss your qualifications and interests to see how we can match you with a suitable opportunity.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 74 
prompt_tokens_used: 58 
total_tokens_used: 132 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said, "Give me a job pretty please." You\'re expressing a polite and hopeful request for employment. Could you tell me a bit more about yourself, such as your skills, interests, or any specific job roles you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "Pretty Please." Could you please clarify what kind of job you\'re interested in or what you mean by "Pretty Please"? Are you referring to a specific company or role?\n\nTo summarize, you\'ve expressed interest in obtaining a job, possibly related to "Pretty Please," but the context isn\'t entirely clear. Could you provide more details?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 118 
prompt_tokens_used: 58 
total_tokens_used: 176 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break it down:\n\n1. **Job Request**: You\'re looking for a job.\n2. **Polite Tone**: You\'ve added "pretty please" to convey a polite and respectful tone.\n\nTo summarize, you\'re seeking employment and are approaching the request in a friendly manner. Could you tell me a bit more about the type of job you\'re interested in or any specific skills you have? This will help me better understand your needs and provide more tailored advice.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a friendly and hopeful way.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Is there a specific field or type of job you\'re interested in, or would you like some guidance on where to start your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you tell me a bit more about what kind of job you're interested in? What are your skills, qualifications, or areas of interest? This will help me better understand how I can assist you.\n\nTo summarize, you're looking for a job and have expressed your request in a friendly manner. Now, let's discuss your qualifications and preferences to see how we can match you with the right opportunity.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and hopeful manner.\n\nTo summarize, you\'re seeking a job and are open to exploring different possibilities. Is there a specific field or type of job you\'re interested in, or would you like some general advice on where to start your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 58 
total_tokens_used: 168 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." Let\'s break it down:\n\n1. **Desire for Employment**: You\'re clearly looking for a job opportunity.\n2. **Polite Approach**: You\'re using a polite and friendly tone, which is great for any job search or interview.\n\nTo help you further, could you tell me a bit more about yourself? What kind of job are you interested in? What skills or experiences do you have that could be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 58 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a somewhat playful manner. Could you please elaborate on what kind of job you're interested in or what skills you have that you think would be relevant for a position? This will help me better understand your request and provide more tailored advice or opportunities. \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, saying "give me a job pretty please." Let\'s break down what you\'re looking for:\n\n1. **Job Desire**: You\'re interested in finding employment.\n2. **Polite Approach**: You\'re using a polite and friendly tone to express your request.\n\nTo help you further, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help tailor our conversation to your needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous manner.\n\nTo summarize, you\'re seeking a job and are open to suggestions or opportunities. Is there a specific field or type of job you\'re interested in? Let\'s discuss your skills and interests to explore potential career paths.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nTo summarize, you\'re expressing interest in finding a job and are hoping for assistance or guidance in your job search. Is there a specific type of job or industry you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You\'ve said, "Give me a job pretty please." This suggests you\'re interested in exploring job opportunities and are approaching the request with a friendly tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you please tell me a bit more about the kind of job you're interested in? What skills do you have, and what are your career aspirations? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but haven't specified the type or industry. Let's discuss your qualifications and interests to explore potential opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that you think would be valuable in the job market? This will help me better understand your needs and provide more tailored advice.\n\nTo summarize, you\'ve said "give me a job pretty please," which suggests you\'re looking for employment opportunities. Let\'s explore this further What are your strengths or areas of interest?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." Let me summarize: You\'re expressing a polite and enthusiastic request for employment opportunities. Is there a specific type of job or industry you\'re interested in? Perhaps we can discuss some options that might suit you. \n\nFor instance, there are various roles available in different sectors, such as retail, beauty, or even technology. If you have any particular skills or interests, feel free to share them so we can explore possibilities together.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 113 
prompt_tokens_used: 58 
total_tokens_used: 171 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in or if there\'s a specific company or role you have in mind? I\'d be happy to help facilitate the conversation.\n\n**Summary of Your Request:**\n- You\'re looking for a job.\n- You\'ve used the phrase "pretty please," which might indicate a polite or specific request.\n- You haven\'t specified a particular job title or industry.\n\nLet\'s continue the conversation to explore your interests and qualifications further', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize your request: You\'re looking for a job opportunity and are expressing your interest in a polite manner.\n\nTo proceed, could you tell me a bit more about the type of job you\'re interested in or what skills you have that might be relevant to a position? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about what you\'re looking for in a job. Could you tell me a bit more about your interests, skills, or any specific roles you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for job opportunities and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you please elaborate on what kind of job you're interested in or what skills you have that might be relevant for a position? This will help me better understand your request and provide more tailored advice or opportunities.\n\nTo summarize, you've expressed a desire for a job, but we haven't discussed specific details yet. Let's explore your interests and qualifications further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and hopeful way.\n\nTo summarize, you\'re seeking a job and are open to possibilities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 117 
prompt_tokens_used: 58 
total_tokens_used: 175 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added "pretty please" to your request. Let\'s break down what you\'re looking for:\n\n1. **Job Request**: You\'re seeking employment.\n2. **Polite Tone**: You\'ve used "pretty please," which indicates a polite and respectful approach.\n\nTo proceed, could you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me better understand your needs and provide more tailored advice or opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said:\n\n- You\'re expressing a polite request for a job opportunity.\n- You haven\'t specified a particular job or industry, but you\'re open to discussing possibilities.\n\nCould you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a position? This will help me better understand your needs and provide more tailored advice.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s start a conversation about your job search. Could you tell me a bit about yourself, such as your background, skills, or any specific job roles you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re looking for a job and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 152 
prompt_tokens_used: 58 
total_tokens_used: 210 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. Let me summarize what you\'ve said:\n\n- You are looking for a job.\n- You\'ve added a polite phrase, "pretty please," to your request.\n\nTo assist you further, could you please provide more details about the type of job you\'re interested in or any specific skills you have? This will help me guide you better. \n\nAlso, I noticed that there are some job listings available on platforms like Indeed, but I didn\'t find any current openings at "Pretty Please Aesthetics" as they are not hiring at this time[2][4]. If you have a specific industry or role in mind, feel free to share', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a friendly and respectful tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a polite touch by saying "pretty please." Let\'s have a conversation about what kind of job you\'re interested in and what skills or experiences you bring to the table.\n\nTo summarize, you\'re looking for a job opportunity, and you\'re open to discussing your qualifications and interests. Is that correct? If so, could you tell me a bit more about the type of job you\'re interested in or any specific skills you have?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about what kind of job you\'re interested in and what skills you bring to the table.\n\nTo summarize, you\'re looking for a job opportunity and are open to discussing your qualifications and interests. Is that correct? If so, could you tell me a bit more about the type of job you\'re interested in or any specific skills you have?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather creative way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and hopeful manner.\n\nTo summarize, you\'re seeking a job and are open to any opportunities that might be available. Is there a specific field or type of job you\'re interested in? Or would you like some general advice on how to approach your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 74 
prompt_tokens_used: 58 
total_tokens_used: 132 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job opportunity in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor. Can you tell me more about the type of job you\'re interested in or what skills you have that might be relevant to a potential employer?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 270 
prompt_tokens_used: 1218 
total_tokens_used: 1488 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for job opportunities, so here are some options across different sectors:\n\n## High-Demand Jobs in 2025\n\n1. **Healthcare Professionals**: Roles like physicians, clinical psychologists, and registered nurses are in high demand due to an aging population and increased healthcare needs[1].\n2. **Engineering Roles**: Civil, structural, and electrical engineers are sought after due to infrastructure needs and technological advancements[1].\n3. **Data Scientists**: With the rise of data-driven decision-making, data scientists are increasingly needed across industries[3].\n\n## Entry-Level and Service Jobs\n\n1. **Barista**: With a steady demand for coffee, barista positions are available, especially in larger coffee chains[3].\n2. **Customer Service Representative**: Many companies offer flexible hours and remote work options for customer service roles[3].\n3. **Retail and Sales**: Positions like retail sales associates or sales representatives are available in various sectors[4].\n\n## Boutique and Creative Jobs\n\n1. **Hair Stylist**: Salons are hiring stylists with creative skills and the ability to work in a fast-paced environment[4].\n2. **Makeup Artist**: Opportunities exist for makeup artists in dynamic teams, requiring strong makeup application skills[4].\n\nThese jobs span different sectors and can be a good starting point for your job search.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 58 
total_tokens_used: 157 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job opportunity, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about what you\'re looking for in a job. Could you tell me a bit about your background, skills, or any specific areas of interest you have? This will help me better understand how I can assist you in finding a suitable job. \n\nTo summarize, you\'re seeking a job and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 58 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone. Can you tell me a bit more about the type of job you\'re interested in or what skills you have to offer? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You said, "Give me a job pretty please." This suggests you\'re looking for assistance in finding employment. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? That way, I can provide more tailored advice or guidance. \n\nTo summarize, you\'re seeking help in obtaining a job, and you\'re open to suggestions or assistance in the job search process.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 58 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a playful touch with "pretty please." Let\'s have a conversation about your job search. Could you tell me a bit more about yourself, such as your education background, any relevant work experience, and what kind of job you\'re interested in? This will help me better understand how I can assist you.\n\nTo summarize, you\'re looking for a job and would like some assistance in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re interested in exploring job opportunities, possibly in a friendly or appealing setting. Could you tell me a bit more about what kind of job you\'re looking for or what interests you? This will help me better understand your needs and provide more tailored advice. \n\nTo summarize, you\'re expressing a desire for employment, but haven\'t specified a particular field or role yet.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire for a job opportunity. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a potential position?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are open to opportunities.\n\nTo better assist you, could you tell me a bit about your background, skills, or any specific areas you\'re interested in? This will help tailor our conversation to find a suitable job fit for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "g i v e   m e   a   j o b   p r e t t y   p l e a s e," which suggests you\'re looking for employment opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 266 
prompt_tokens_used: 1218 
total_tokens_used: 1484 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for job opportunities. Here are some in-demand jobs for 2025, along with a note about a specific company that isn't hiring at the moment:\n\n## In-Demand Jobs for 2025\n\n1. **Veterinarian**: Median salary $139,999, with a 124% increase in job listings over the past three years[1].\n2. **Sales Representative**: Median salary $182,487, with a 76% increase in job listings[1].\n3. **Physician**: Median salary $225,000, with a 76% increase in job listings[1].\n4. **Data Scientist**: Median wage $51.93 per hour, with a 9% job outlook increase from 2025 to 2033[3].\n5. **Actuary**: Median wage $57.69 per hour, with a 9% job outlook increase from 2025 to 2033[3].\n\n## Specific Company Update\n\n- **Pretty Please Aesthetics**: Currently, they are not hiring for any positions. However, they encourage interested individuals to send their resumes for potential future opportunities[4].\n\nIf you're looking for job opportunities, consider exploring these in-demand roles or reaching out to companies like Pretty Please Aesthetics for future openings.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 129 
prompt_tokens_used: 58 
total_tokens_used: 187 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Let's break down what you've said and explore how we can assist you in finding a job or discussing your career aspirations.\n\nYou've expressed a desire for a job, which suggests you're either looking for new opportunities or perhaps transitioning into a different field. Could you tell me a bit more about your background, skills, or the type of job you're interested in? This will help me better understand how to assist you. \n\nAlso, are there any specific industries or roles that you're particularly interested in? Knowing this can help tailor our conversation to your needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 111 
prompt_tokens_used: 58 
total_tokens_used: 169 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking for assistance in a polite manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are open to guidance or support in your job search.\n\nTo summarize, you\'re seeking help in finding a job, and you\'re approaching the request with a friendly and hopeful tone. Is there a specific type of job or industry you\'re interested in, or would you like some general advice on how to proceed with your job search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 58 
total_tokens_used: 168 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, using a playful tone by saying "give me a job pretty please." Let\'s break down what you\'re looking for:\n\n1. **Job Interest**: You\'re interested in finding a job.\n2. **Tone**: You\'re approaching the request with a lighthearted and polite demeanor.\n\nTo help you further, could you tell me a bit more about your skills, interests, or any specific job roles you\'re considering? This will help tailor our conversation to your needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 58 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experience that might help narrow down some options?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 107 
prompt_tokens_used: 58 
total_tokens_used: 165 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful manner. Could you please tell me a bit more about yourself and what kind of job you're interested in? What are your skills, education, and any relevant experiences you have? This will help me better understand how I can assist you in your job search.\n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specifics yet. Let's explore your qualifications and interests further to see how we can match you with a suitable opportunity.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 229 
prompt_tokens_used: 58 
total_tokens_used: 287 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire for a job and are open to discussing potential opportunities. Is there a specific type of job or industry you\'re interested in? Let\'s explore some options together. \n\nHere are some in-demand jobs for 2025 that might interest you:\n\n- **Healthcare Professionals**: Roles like physicians, clinical psychologists, and registered nurses are in high demand due to an aging population and the need for skilled healthcare workers[1].\n- **Engineering Roles**: Civil, electrical, and structural engineers are sought after due to infrastructure needs and technological advancements[1].\n- **Data Scientists**: With the increasing use of data in decision-making, data scientists are highly valued across various industries[3].\n- **Customer Service Representatives**: These roles often offer flexible work arrangements and are essential in many sectors[3].\n\nWhich of these areas resonates with you, or do you have another field in mind?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 84 
prompt_tokens_used: 58 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for assistance in finding a position.\n\nTo better understand your needs and qualifications, could you tell me a bit about your background, skills, or any specific job roles you\'re interested in? This will help me provide more tailored advice or guidance.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 113 
prompt_tokens_used: 58 
total_tokens_used: 171 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "Pretty Please." Could you clarify what kind of job you\'re looking for at Pretty Please or if there\'s something specific about the company that interests you? I\'d like to understand your request better.\n\n**Summary of Your Request:**\n- You\'re interested in a job.\n- You mentioned "Pretty Please," which might be related to a specific company or role.\n\nLet\'s discuss this further What are your skills or interests, and how do they align with what you\'re looking for?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Let's have a conversation about your job interests and qualifications. Could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that might be relevant? \n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specifics yet. Let's explore that further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 128 
prompt_tokens_used: 58 
total_tokens_used: 186 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'d like to approach this in a friendly manner. Let\'s break down what you\'ve said:\n\n1. **Job Request**: You\'re asking for a job, which indicates you\'re currently looking for employment opportunities.\n2. **Polite Tone**: The use of "pretty please" suggests you\'re approaching this with a polite and respectful attitude.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities in a friendly and respectful manner. How can I assist you further in your job search? Are there any specific industries or roles you\'re interested in?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 69 
prompt_tokens_used: 58 
total_tokens_used: 127 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, using a playful tone by saying "give me a job pretty please." You\'re likely looking for assistance or guidance in finding employment. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a potential position?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 58 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." To summarize, you\'re expressing a polite and enthusiastic request for employment. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to a position? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand how I can assist you. \n\nTo summarize, you've expressed a desire for a job, but haven't specified the type of role you're looking for. Let's explore your options together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 58 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a somewhat playful manner. Could you tell me a bit more about what kind of job you're interested in? What are your skills or areas of interest? This will help me better understand how I can assist you.\n\nTo summarize, you've expressed a desire for a job, but haven't specified the type of role you're looking for. Let's discuss your qualifications and preferences to explore potential opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment and are approaching the request with a lighthearted tone.\n\nLet\'s discuss your job search further. What kind of job are you interested in? Do you have any specific skills or experiences that you think would be relevant for a position?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 58 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are eager to find a position. Could you tell me a bit more about your background, interests, or the type of job you\'re interested in? This will help me better understand how to assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 58 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for assistance or guidance in finding a suitable position.\n\nTo better understand your needs, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experiences that might help narrow down some options?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a polite manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are expressing your request in a friendly and hopeful way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for assistance or guidance in finding a suitable position.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 119 
prompt_tokens_used: 58 
total_tokens_used: 177 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that. You said, "Give me a job pretty please." This suggests you\'re looking for assistance in finding employment. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or guidance. \n\nTo summarize, you\'re seeking a job and would like some help in that process. Is there anything specific you\'re looking for in a job, such as a particular industry or work environment?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 58 
total_tokens_used: 153 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Let's have a conversation about what you're looking for in a job. Could you tell me a bit more about your interests, skills, or any specific roles you're interested in? This will help me better understand how to assist you.\n\nTo summarize, you've expressed a desire for a job, but we haven't discussed any specific details yet. Let's explore your qualifications and preferences together.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve said "give me a job pretty please." Let me summarize what you\'ve expressed: You\'re politely and humorously asking for a job opportunity. \n\nNow, let\'s have a conversation about what kind of job you might be interested in. Could you tell me a bit about your skills, interests, or any specific fields you\'re considering? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 80 
prompt_tokens_used: 58 
total_tokens_used: 138 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response.\n\nTo better understand your needs, could you tell me a bit about your background, skills, or any specific job roles you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 58 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are expressing your request in a polite and humorous manner.\n\nTo summarize, you\'re seeking a job and are open to discussing potential opportunities. Let\'s explore what kind of job you might be interested in and what skills or experiences you have to offer. Could you tell me a bit more about your background and what you\'re looking for in a role?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 159 
prompt_tokens_used: 1218 
total_tokens_used: 1377 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for job opportunities related to "Pretty Please." Here are a few options:\n\n1. **Pretty Please Aesthetics**: Currently, they are not hiring, but they encourage sending resumes for future opportunities. They are based in Sacramento and Roseville, focusing on aesthetics services[2].\n\n2. **Pretty Please Boutique Jobs**: There are numerous job listings available under the name "Pretty Please Boutique" on Indeed, including roles like Retail Sales Associate, Floral Designer, and Model. These positions are diverse and not necessarily related to the aesthetics industry[4].\n\nIf you\'re interested in specific job roles or industries, it might be helpful to explore more targeted job boards or career platforms. Additionally, checking local listings or company websites directly can provide more precise information about available positions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests that you\'re looking for employment and are hoping for assistance in finding a position.\n\nTo better understand your needs, could you tell me a bit more about yourself? What kind of job are you interested in? Do you have any specific skills or experiences that you think would be relevant to a potential employer?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to help you with that in a polite manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment and are hoping for assistance in finding a suitable position.\n\nCould you tell me a bit more about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in or if there\'s a specific company or role you have in mind? I\'d like to understand your request better.\n\nTo summarize, you\'ve expressed a desire for a job and used the phrase "pretty please," which suggests a polite and hopeful tone. If you have any specific details or preferences, feel free to share them so I can assist you more effectively.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 58 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking for assistance in a polite manner. You\'ve said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are hoping for some guidance or support in your job search.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This information will help me provide more tailored advice or suggestions for your career path.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 120 
prompt_tokens_used: 58 
total_tokens_used: 178 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful way. Let\'s break down what you\'ve said:\n\n- **Request for a Job**: You\'re asking for a job, which indicates you\'re currently looking for employment.\n- **Tone**: The use of "pretty please" suggests a lighthearted or humorous approach to the request.\n\nTo engage in a neutral conversation, I could ask: "What kind of job are you interested in? Are there any specific industries or roles you\'re considering?" This opens up a dialogue to explore your interests and qualifications further.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 58 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in? Are you looking for something specific or just exploring opportunities?\n\nTo summarize, you\'ve expressed a desire for a job and used a polite phrase to emphasize your request. If you could provide more details about your interests or qualifications, I\'d be happy to help further.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 70 
prompt_tokens_used: 58 
total_tokens_used: 128 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said: You\'re expressing a polite request for a job opportunity. Is that correct? If so, could you tell me a bit more about the type of job you\'re interested in or any specific skills you have?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 58 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in? Are you looking for something specific or just exploring opportunities? Let\'s discuss what you\'re looking for, and I can help guide you through the process.\n\n**Summary of Your Request:**\n- You\'re seeking a job.\n- You\'ve used the phrase "pretty please," which suggests a polite or hopeful tone.\n- You haven\'t specified a particular job type or industry.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 58 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. Could you clarify what kind of job you\'re interested in or what you mean by "pretty please"? This will help me better understand your needs and provide a more accurate response.\n\n**Summary of Your Request:**\n- You\'re seeking a job.\n- You\'ve added "pretty please" to your request, which might indicate a polite or urgent tone.\n\nLet\'s discuss further to see how I can assist you', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 58 
total_tokens_used: 154 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way, saying "give me a job pretty please." You\'re likely expressing a desire for employment assistance or guidance. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you. \n\nTo summarize, you\'re seeking a job and would appreciate any help or advice in finding one. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 58 
total_tokens_used: 158 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a somewhat playful manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities, possibly with a bit of humor or lightheartedness.\n\nTo summarize, you\'re expressing a desire for a job, but you haven\'t specified any particular field or qualifications. Could you tell me a bit more about your interests or skills? That way, I can better assist you in exploring potential job opportunities.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are expressing your request in a friendly and polite way.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 58 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, using a playful tone with "pretty please." Let\'s have a conversation about your job aspirations. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that you think would be valuable in the job market? This will help us explore potential opportunities together. \n\nTo summarize, you\'re looking for a job and are open to discussing your interests and qualifications. Is that correct?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 92 
prompt_tokens_used: 58 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included the phrase "pretty please." Let me summarize what you\'ve said:\n\n- You\'re expressing a polite request for a job opportunity.\n- The phrase "pretty please" suggests a friendly and hopeful tone.\n\nCould you tell me a bit more about the type of job you\'re interested in or what skills you bring to the table? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 130 
prompt_tokens_used: 58 
total_tokens_used: 188 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "pretty please." Could you clarify what kind of job you\'re interested in? Are you referring to a specific company or role, such as a position at a salon like Pretty Please Hair Salon? Let\'s discuss what you\'re looking for in a job and see how we can assist you.\n\nTo summarize, you\'ve expressed interest in finding a job and used the phrase "pretty please," which might be related to a salon or another context. Could you provide more details about your job preferences or any specific skills you have? This will help us tailor our conversation to your needs.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 58 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. You said, "Give me a job pretty please." This suggests that you\'re looking for employment opportunities and are approaching the request with a bit of humor.\n\nTo summarize, you\'re expressing a desire to find a job, and you\'re doing so in a lighthearted way. Could you tell me a bit more about what kind of job you\'re interested in or what skills you have that might be relevant to potential employers?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 58 
total_tokens_used: 166 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you mentioned "Pretty Please." Could you clarify what type of job you\'re interested in? Are you looking for opportunities at a specific company or in a particular industry? Let\'s discuss your career aspirations and see how we can assist you.\n\n**Summary of Your Request:**\n- You\'re seeking a job.\n- You mentioned "Pretty Please," which might refer to a company or a specific type of job.\n- You\'re open to discussing your career interests and finding a suitable opportunity.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 80 
prompt_tokens_used: 58 
total_tokens_used: 138 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job in a playful manner. You\'ve said, "Give me a job pretty please." This suggests that you\'re looking for employment and are hoping for a positive response. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 58 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're asking for a job in a rather playful way. Could you tell me a bit more about what kind of job you're interested in? What are your skills and experiences? Let's have a conversation about how we can help you find the right opportunity. \n\nTo summarize, you're looking for a job and are approaching it with a friendly tone. Is there a specific industry or role you're interested in?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 58 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve included "pretty please" in your request. Let me summarize what you\'ve said:\n\n- You\'re expressing a polite and enthusiastic interest in obtaining a job.\n- You haven\'t specified a particular type of job or industry.\n\nCould you tell me a bit more about what kind of job you\'re interested in or what skills you have? This will help me better understand your needs and provide more tailored advice.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 58 
total_tokens_used: 146 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a lighthearted tone.\n\nTo better assist you, could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 106 
prompt_tokens_used: 58 
total_tokens_used: 164 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve added a polite touch by saying "pretty please." Let\'s have a conversation about what kind of job you\'re interested in and what skills you bring to the table.\n\nTo summarize, you\'re looking for a job opportunity and are open to discussing your qualifications and interests. Could you tell me a bit more about your background, skills, or any specific job roles you\'re interested in? This will help us explore potential opportunities that might be a good fit for you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 58 
total_tokens_used: 144 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking me to assist you in a polite manner. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are open to opportunities. Could you tell me a bit more about your background, skills, or the type of job you\'re interested in? This will help me better understand how I can assist you.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 104 
prompt_tokens_used: 58 
total_tokens_used: 162 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'d like me to assist you in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and would appreciate any help or guidance in finding a suitable position.\n\nLet\'s discuss what kind of job you might be interested in. Are you looking for something specific, or are you open to various types of roles? Additionally, do you have any particular skills or qualifications that could help narrow down the search?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful manner. To summarize, you said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request in a lighthearted way.\n\nLet\'s have a more detailed conversation about what kind of job you\'re interested in. Could you tell me a bit about your skills, experience, or any specific fields you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 58 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job, and you\'re asking for one in a polite manner. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are hoping for assistance in finding a suitable position.\n\nTo better assist you, could you tell me a bit more about your skills, interests, or any specific job roles you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 58 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're expressing a desire for a job in a playful manner. Could you tell me a bit more about what kind of job you're interested in or what skills you have that might be relevant to a position? This will help me better understand your needs and provide more tailored advice or suggestions. \n\nTo summarize, you've asked for a job in a polite and humorous way, but we haven't discussed any specific details yet. Let's explore your interests and qualifications further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 58 
total_tokens_used: 139 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re expressing a desire for a job opportunity. You\'ve said, "Give me a job pretty please." This suggests you\'re looking for employment and are hoping for a favorable response.\n\nTo better understand your needs, could you please tell me a bit about your background, skills, or any specific job areas you\'re interested in? This will help me provide more tailored advice or suggestions.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [56269]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 58 
total_tokens_used: 159 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job in a rather playful way. You said, "Give me a job pretty please." This suggests you\'re looking for employment opportunities and are approaching the request with a friendly and optimistic tone.\n\nTo summarize, you\'re seeking a job and are open to exploring different options. Could you tell me a bit more about your background, skills, or any specific job roles you\'re interested in? This will help me better understand how to assist you in your job search.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 62, in transcribe_user_speech
    transcription = audioStore.transcribeAudio(f"./user_audio_files/{file.filename}")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioStore.py", line 33, in transcribeAudio
    audio = AudioSegment.from_wav(audio_file_name)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/audio_segment.py", line 808, in from_wav
    return cls.from_file(file, 'wav', parameters=parameters)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/audio_segment.py", line 773, in from_file
    raise CouldntDecodeError(
pydub.exceptions.CouldntDecodeError: Decoding failed. ffmpeg returned error code: 183

Output from ffmpeg/avlib:

ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[wav @ 0x11f706470] invalid start code [243][252][177][248] in RIFF header
[in#0 @ 0x11f706220] Error opening input: Invalid data found when processing input
Error opening input file ./user_audio_files/userResponse.wav.
Error opening input files: Invalid data found when processing input

INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 58 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking for a job, and you\'ve mentioned "Pretty Please." Could you clarify what kind of job you\'re interested in or what you mean by "Pretty Please"? Are you referring to a specific company or role? Let\'s discuss this further to understand your needs better.\n\nTo summarize, you\'ve expressed a desire for a job and mentioned "Pretty Please," but the context isn\'t entirely clear. Could you provide more details?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 40 
total_tokens_used: 137 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re saying "hello." Let\'s start our conversation You\'ve initiated the greeting, which is a great way to begin. Could you tell me a bit more about what you\'d like to discuss or share today? I\'m here to listen and engage in a conversation. \n\nTo summarize, you\'ve said "hello," which is a friendly and common way to start a conversation. Now, feel free to add more context or topics you\'re interested in exploring.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 70 
prompt_tokens_used: 59 
total_tokens_used: 129 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re asking about the weather today. Could you please provide more context or specify a location? I\'d be happy to help you find out what the weather is like today.\n\nTo summarize, you asked, "What\'s the weather today?" If you provide a specific location, I can try to give you a more accurate answer.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 23 
prompt_tokens_used: 1208 
total_tokens_used: 1231 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like your query is empty. Could you please provide more details or clarify what you need help with?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 35 
prompt_tokens_used: 1208 
total_tokens_used: 1243 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 36 
prompt_tokens_used: 1208 
total_tokens_used: 1244 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking for? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 137 
prompt_tokens_used: 55 
total_tokens_used: 192 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re starting with a casual greeting: "Hello, how\'s it going?" This is a common way to begin a conversation, especially in informal settings. It\'s a friendly and approachable way to ask about someone\'s day or well-being.\n\nTo respond, you might say something like: "Hello I\'m doing well, thanks. How about you?" This acknowledges their greeting and invites them to share a bit about themselves.\n\nIf you\'d like to summarize what they said, since they haven\'t shared much yet, you could simply say: "You started with a friendly greeting, and now we\'re ready to chat. What would you like to talk about?"', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58186]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 37 
prompt_tokens_used: 1208 
total_tokens_used: 1245 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is empty. Could you please provide more details or clarify what you are looking for? I'm here to help with any information or questions you might have", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58493]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 61 
prompt_tokens_used: 40 
total_tokens_used: 101 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re saying "hello." Could you please elaborate on what you\'d like to discuss or share? I\'m here to listen and engage in a conversation with you.\n\nTo summarize, you\'ve initiated a greeting, and I\'m waiting for further context or topics you\'d like to explore.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58599]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 40 
total_tokens_used: 133 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'ve typed out the word "hello" with spaces between each letter. Could you clarify what you\'d like to discuss or what\'s on your mind? I\'m here to listen and engage in a conversation. \n\nTo summarize, you\'ve said "h e l l o," but I\'m not sure what you\'re referring to. Is there something specific you\'d like to talk about, perhaps related to the word itself or something else entirely?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58648]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 36 
prompt_tokens_used: 1208 
total_tokens_used: 1244 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is empty. Could you please provide more details or clarify what you are asking? I'm here to help with any information or questions you might have.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 49 
total_tokens_used: 130 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re using a mix of greetings and expressions. You said "o k a y," which is an agreement or acknowledgment, followed by "h e l l o" and "h e y," which are informal greetings. It sounds like you\'re trying to initiate a conversation. Could you tell me a bit more about what you\'d like to discuss or what\'s on your mind?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58706]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 55 
total_tokens_used: 160 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re starting with a casual greeting: "Hello, how\'s it going?" This is a friendly and informal way to begin a conversation. It\'s often used to show interest in how the other person is doing.\n\nTo respond, I could say: "Hello I\'m doing well, thank you. How about you?" This keeps the conversation light and open.\n\nCould you tell me a bit more about what you\'d like to discuss or share? I\'m here to listen and engage in a conversation.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [58986]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 51 
total_tokens_used: 132 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re starting a sentence with "did someone want." Could you please complete your thought or question? I\'m here to listen and help facilitate our conversation. \n\nIf you\'re asking if someone wanted something specific, please provide more context so I can better understand and respond accordingly. \n\nTo summarize, you\'ve started a sentence but haven\'t completed it. Could you please provide more details?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 137 
prompt_tokens_used: 55 
total_tokens_used: 192 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like you\'re starting a casual conversation with the phrase "hello, how\'s it going?" This is a common way to greet someone and inquire about their well-being. It\'s often used in informal settings and is typically followed by a brief, positive response.\n\nTo respond neutrally, you might say: "Hello I\'m doing well, thanks. How about you?" This acknowledges their greeting and invites them to share a bit about themselves.\n\n**Summary of what you said:**\n- You initiated a casual greeting with "hello, how\'s it going?"\n- This phrase is commonly used in informal settings to start a conversation and show interest in the other person\'s day.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [59140]
