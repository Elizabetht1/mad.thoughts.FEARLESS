INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 58, in generateText
    f"completion_tokens_used: {response.usage.completition_tokens} \n"
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 892, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'CompletionUsage' object has no attribute 'completition_tokens'. Did you mean: 'completion_tokens'?
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26137]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 62, in generateText
    res = response.content.choices.delta.content
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26160]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 62, in generateText
    print(response.content)
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26187]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 884, in __getattr__
    return pydantic_extra[item]
           ~~~~~~~~~~~~~~^^^^^^
KeyError: 'content'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 63, in generateText
    res = response.content.choices.delta.content
          ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydantic/main.py", line 886, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
AttributeError: 'ChatCompletionChunk' object has no attribute 'content'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26205]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 3 
prompt_tokens_used: 28 
total_tokens_used: 31 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 5 
prompt_tokens_used: 28 
total_tokens_used: 33 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 7 
prompt_tokens_used: 28 
total_tokens_used: 35 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 9 
prompt_tokens_used: 28 
total_tokens_used: 37 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 11 
prompt_tokens_used: 28 
total_tokens_used: 39 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 13 
prompt_tokens_used: 28 
total_tokens_used: 41 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 15 
prompt_tokens_used: 28 
total_tokens_used: 43 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 17 
prompt_tokens_used: 28 
total_tokens_used: 45 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 19 
prompt_tokens_used: 28 
total_tokens_used: 47 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 21 
prompt_tokens_used: 28 
total_tokens_used: 49 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 23 
prompt_tokens_used: 28 
total_tokens_used: 51 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 25 
prompt_tokens_used: 28 
total_tokens_used: 53 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 27 
prompt_tokens_used: 28 
total_tokens_used: 55 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 29 
prompt_tokens_used: 28 
total_tokens_used: 57 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 28 
total_tokens_used: 59 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 33 
prompt_tokens_used: 28 
total_tokens_used: 61 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 35 
prompt_tokens_used: 28 
total_tokens_used: 63 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 37 
prompt_tokens_used: 28 
total_tokens_used: 65 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 28 
total_tokens_used: 67 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 41 
prompt_tokens_used: 28 
total_tokens_used: 69 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 43 
prompt_tokens_used: 28 
total_tokens_used: 71 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 45 
prompt_tokens_used: 28 
total_tokens_used: 73 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 47 
prompt_tokens_used: 28 
total_tokens_used: 75 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 49 
prompt_tokens_used: 28 
total_tokens_used: 77 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 51 
prompt_tokens_used: 28 
total_tokens_used: 79 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 53 
prompt_tokens_used: 28 
total_tokens_used: 81 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 55 
prompt_tokens_used: 28 
total_tokens_used: 83 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 57 
prompt_tokens_used: 28 
total_tokens_used: 85 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 59 
prompt_tokens_used: 28 
total_tokens_used: 87 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 61 
prompt_tokens_used: 28 
total_tokens_used: 89 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 63 
prompt_tokens_used: 28 
total_tokens_used: 91 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 65 
prompt_tokens_used: 28 
total_tokens_used: 93 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 67 
prompt_tokens_used: 28 
total_tokens_used: 95 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 69 
prompt_tokens_used: 28 
total_tokens_used: 97 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 71 
prompt_tokens_used: 28 
total_tokens_used: 99 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 28 
total_tokens_used: 101 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 75 
prompt_tokens_used: 28 
total_tokens_used: 103 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 28 
total_tokens_used: 105 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 28 
total_tokens_used: 109 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 28 
total_tokens_used: 111 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 28 
total_tokens_used: 113 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 28 
total_tokens_used: 117 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 28 
total_tokens_used: 119 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 28 
total_tokens_used: 121 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 95 
prompt_tokens_used: 28 
total_tokens_used: 123 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 97 
prompt_tokens_used: 28 
total_tokens_used: 125 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 99 
prompt_tokens_used: 28 
total_tokens_used: 127 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 28 
total_tokens_used: 129 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 103 
prompt_tokens_used: 28 
total_tokens_used: 131 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 105 
prompt_tokens_used: 28 
total_tokens_used: 133 

INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 106 
prompt_tokens_used: 28 
total_tokens_used: 134 

INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26256]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 64, in generateText
    logger.info("potential choice from perplexity\n"+choice)
                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~
TypeError: can only concatenate str (not "Choice") to str
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26356]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello'})
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 34, in generate_conversation
    for r in questionText:
             ^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 67, in generateText
    res = response.choices[0].message['text']['content']
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
KeyError: 'text'
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26377]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 1 
prompt_tokens_used: 28 
total_tokens_used: 29 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 3 
prompt_tokens_used: 28 
total_tokens_used: 31 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Thank', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 5 
prompt_tokens_used: 28 
total_tokens_used: 33 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' you for', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 7 
prompt_tokens_used: 28 
total_tokens_used: 35 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' reaching out', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 9 
prompt_tokens_used: 28 
total_tokens_used: 37 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='. I', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 11 
prompt_tokens_used: 28 
total_tokens_used: 39 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' appreciate your', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 13 
prompt_tokens_used: 28 
total_tokens_used: 41 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' interest in', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 15 
prompt_tokens_used: 28 
total_tokens_used: 43 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' working with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 17 
prompt_tokens_used: 28 
total_tokens_used: 45 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' us.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us.'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 19 
prompt_tokens_used: 28 
total_tokens_used: 47 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Before we', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 21 
prompt_tokens_used: 28 
total_tokens_used: 49 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' proceed,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed,'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 23 
prompt_tokens_used: 28 
total_tokens_used: 51 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' could you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 25 
prompt_tokens_used: 28 
total_tokens_used: 53 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' tell me', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 27 
prompt_tokens_used: 28 
total_tokens_used: 55 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' a bit', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 29 
prompt_tokens_used: 28 
total_tokens_used: 57 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' about your', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 28 
total_tokens_used: 59 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' background and', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 33 
prompt_tokens_used: 28 
total_tokens_used: 61 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' what type', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 35 
prompt_tokens_used: 28 
total_tokens_used: 63 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' of role', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': 'Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role'})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 37 
prompt_tokens_used: 28 
total_tokens_used: 65 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" you're", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 28 
total_tokens_used: 67 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' interested in', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 41 
prompt_tokens_used: 28 
total_tokens_used: 69 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='? This', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 43 
prompt_tokens_used: 28 
total_tokens_used: 71 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' will help', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 45 
prompt_tokens_used: 28 
total_tokens_used: 73 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' me better', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 47 
prompt_tokens_used: 28 
total_tokens_used: 75 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' understand how', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 49 
prompt_tokens_used: 28 
total_tokens_used: 77 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' your skills', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 51 
prompt_tokens_used: 28 
total_tokens_used: 79 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' and experiences', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 53 
prompt_tokens_used: 28 
total_tokens_used: 81 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' might align', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 55 
prompt_tokens_used: 28 
total_tokens_used: 83 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' with our', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 57 
prompt_tokens_used: 28 
total_tokens_used: 85 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" company's", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 59 
prompt_tokens_used: 28 
total_tokens_used: 87 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' needs.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs."})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 61 
prompt_tokens_used: 28 
total_tokens_used: 89 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' Additionally,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally,"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 63 
prompt_tokens_used: 28 
total_tokens_used: 91 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' if you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 65 
prompt_tokens_used: 28 
total_tokens_used: 93 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' have a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 67 
prompt_tokens_used: 28 
total_tokens_used: 95 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' resume or', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 69 
prompt_tokens_used: 28 
total_tokens_used: 97 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' any relevant', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 71 
prompt_tokens_used: 28 
total_tokens_used: 99 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' documents,', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents,"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 73 
prompt_tokens_used: 28 
total_tokens_used: 101 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' feel free', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 75 
prompt_tokens_used: 28 
total_tokens_used: 103 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' to share', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 77 
prompt_tokens_used: 28 
total_tokens_used: 105 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' them with', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' me.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me."})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 81 
prompt_tokens_used: 28 
total_tokens_used: 109 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=" Let's", function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 28 
total_tokens_used: 111 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' have a', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 85 
prompt_tokens_used: 28 
total_tokens_used: 113 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' conversation about', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' how you', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 89 
prompt_tokens_used: 28 
total_tokens_used: 117 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' might fit', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 28 
total_tokens_used: 119 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content=' in here', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit in here"})
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 28 
total_tokens_used: 121 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason='stop', index=0, logprobs=None, message={'role': 'assistant', 'content': "Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how your skills and experiences might align with our company's needs. Additionally, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might fit in here."})
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26401]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 108 
prompt_tokens_used: 28 
total_tokens_used: 136 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but let's take a moment to discuss your qualifications and how they might align with our current or future opportunities. Could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, have you had a chance to look at our company's current job postings or would you like some information on how to apply for positions that might be a good fit for you?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 28, in generate_conversation
    questionText = textGen.generateText(
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/textGen.py", line 66, in generateText
    res = response.choices[0].message['content']
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
TypeError: 'ChatCompletionMessage' object is not subscriptable
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26465]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 288 
prompt_tokens_used: 28 
total_tokens_used: 316 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through some strategies to help you find a job that suits your skills and interests.\n\nCould you tell me a bit about your background, skills, and what kind of job you're looking for? This will help me provide more tailored advice.\n\nAdditionally, here are some general tips that might be helpful:\n\n1. **Gather Your Information**: Make sure you have all your work history, skills, education, and references ready. This will help you prepare a strong resume and cover letter[1].\n\n2. **Search Online**: Use job search engines like LinkedIn, Indeed, and Glassdoor to find opportunities that match your criteria[1].\n\n3. **Network**: Share your job search with friends and family, and consider attending job fairs or networking events[1].\n\n4. **Consider What You Love**: Think about what motivates you and what kind of work environment you prefer. This can help you find a job that you'll truly enjoy[2].\n\n5. **Develop Your Skills**: If you're looking to transition into a new field, consider taking courses or getting certifications to enhance your skills[2].\n\nLet's discuss these points further and see how they might apply to your situation. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [26536]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 28 
total_tokens_used: 110 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit more about yourself and what kind of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, have you had a chance to look at our current job openings or is there a specific position you're hoping to explore?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 15, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: pplx-rKV*****************************************LC9b. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [27739]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 168 
prompt_tokens_used: 28 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I don't have the authority to offer you a job directly. Instead, I can guide you through some strategies that might help you find a suitable position.\n\nFirst, let's talk about your skills and interests. What type of job are you looking for? Have you considered any specific industries or roles that align with your strengths and passions?\n\nAdditionally, have you prepared a resume and cover letter? These are essential tools for applying to jobs. If you need help with those, I can provide some tips or resources.\n\nLastly, networking can be very effective. Have you connected with anyone in your desired field or attended any job fairs recently?\n\nLet's explore these areas further and see how we can assist you in your job search.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.467762 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.798412 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 15, in generateAudio
    response = client.audio.speech.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/resources/audio/speech.py", line 96, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1049, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1098, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1049, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1098, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 308 
prompt_tokens_used: 28 
total_tokens_used: 336 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I'm glad you're interested in exploring opportunities with us. However, I'd like to clarify that we typically follow a structured process for hiring. This involves reviewing resumes, conducting interviews, and assessing candidates based on specific job requirements.\n\nBefore we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me understand how your skills and interests might align with our current openings. Additionally, I can provide you with some tips on how to find job opportunities that might be a good fit for you.\n\nHere are some general tips that might be helpful:\n\n1. **Gather Your Information**: Make sure you have all your work history, skills, education, and references ready. This will help you tailor your applications to specific job openings[1].\n\n2. **Search Online**: Use job search engines like LinkedIn, Indeed, and Glassdoor to find opportunities that match your skills and interests[1].\n\n3. **Network**: Let your friends, family, and community know you're looking for a job. They might have connections that can help[1].\n\n4. **Consider Your Passion**: Think about what you enjoy doing and look for roles that align with those interests[2].\n\n5. **Develop Your Skills**: Take courses or get certifications to enhance your qualifications for the jobs you're interested in[2].\n\nLet's discuss how these strategies might apply to your situation. What are your strengths and what kind of job are you hoping to find?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 324, in jsonable_encoder
    data = dict(obj)
           ^^^^^^^^^
TypeError: '_ssl._SSLSocket' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 329, in jsonable_encoder
    data = vars(obj)
           ^^^^^^^^^
TypeError: vars() argument must have __dict__ attribute

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 332, in jsonable_encoder
    raise ValueError(errors) from e
ValueError: [TypeError("'_ssl._SSLSocket' object is not iterable"), TypeError('vars() argument must have __dict__ attribute')]
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [27830]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 87 
prompt_tokens_used: 28 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I appreciate your enthusiasm, but let's take a moment to discuss the position and how you might be a good fit. Could you tell me a bit about your background and what skills you think would make you suitable for a role here? Additionally, what kind of job are you interested in, and what do you know about our company? This will help us have a more productive conversation.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 324, in jsonable_encoder
    data = dict(obj)
           ^^^^^^^^^
TypeError: '_ssl._SSLSocket' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 329, in jsonable_encoder
    data = vars(obj)
           ^^^^^^^^^
TypeError: vars() argument must have __dict__ attribute

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 333, in jsonable_encoder
    return jsonable_encoder(
           ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 332, in jsonable_encoder
    raise ValueError(errors) from e
ValueError: [TypeError("'_ssl._SSLSocket' object is not iterable"), TypeError('vars() argument must have __dict__ attribute')]
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28066]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 115 
prompt_tokens_used: 28 
total_tokens_used: 143 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might be a good fit for you.\n\nCould you tell me a bit about your background, skills, and what type of job you're interested in? This will help me provide you with more tailored advice or resources. Additionally, have you considered using job search platforms like LinkedIn or Indeed to explore available positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('test')
            ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named 'test' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28253]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 78 
prompt_tokens_used: 28 
total_tokens_used: 106 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. However, before we proceed, could you please tell me a bit about yourself? What kind of role are you interested in, and what skills or experiences do you think would make you a strong candidate for our company? This will help me better understand how we might be able to assist you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('./generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named './generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28286]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 79 
prompt_tokens_used: 28 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable in a position here?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('./generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named './generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28329]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 28 
total_tokens_used: 142 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. However, I'd like to discuss your qualifications and how they align with our current or future opportunities. Could you please tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how your skills and interests might fit into our organization.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 29, in generateAudio
    bytes = audioZip.read('generated_audio_transcripts/test.zip')
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1572, in read
    with self.open(name, "r", pwd) as fp:
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1609, in open
    zinfo = self.getinfo(name)
            ^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/zipfile/__init__.py", line 1537, in getinfo
    raise KeyError(
KeyError: "There is no item named 'generated_audio_transcripts/test.zip' in the archive"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28351]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 124 
prompt_tokens_used: 28 
total_tokens_used: 152 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm for working with us. However, I'd like to discuss a few things before we proceed. Could you tell me a bit about your background and what kind of role you're interested in? This will help me better understand how your skills might align with our company's needs.\n\nAlso, if you have a resume or any relevant experience, it would be great if you could share that with me. This will give us a solid foundation for our conversation.\n\nLet's chat more about what you're looking for and how you think you could contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.455468 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28377]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 109 
prompt_tokens_used: 28 
total_tokens_used: 137 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your interest in working with us. Before we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me better understand how you might fit into our organization.\n\nAlso, if you have a resume or any relevant experience, feel free to share that with me. It's always helpful to have a clear picture of your qualifications and skills.\n\nLet's have a conversation about your career goals and how they align with our company's opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 31, in generateAudio
    bytes = fin.read()
            ^^^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa9 in position 10: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28487]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 150 
prompt_tokens_used: 28 
total_tokens_used: 178 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I understand that you're looking for a job, and I'm happy to discuss potential opportunities with you. However, I need to clarify that we typically follow a formal hiring process. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how we might be able to assist you. \n\nAlso, have you had a chance to look at our company's job listings or any specific positions that align with your interests? We can discuss those further if you'd like. \n\nLet's start with your qualifications and what you're looking for in a job. That way, we can explore if there's a good fit here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28567]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 164 
prompt_tokens_used: 28 
total_tokens_used: 192 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I appreciate your enthusiasm, but let's take a moment to discuss your qualifications and how they align with our current job openings. Could you tell me a bit about your background, skills, and what you're looking for in a role? This will help me understand how you might fit into our organization. \n\nAlso, I'd like to share some general advice on job searching. It's important to tailor your resume and cover letter to the specific job you're applying for, and to be prepared to talk about your skills and experiences during an interview. Networking and attending job fairs can also be very beneficial. \n\nIf you have any questions about our company or the positions available, feel free to ask. Let's have a conversation about how you can contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28646]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 117 
prompt_tokens_used: 28 
total_tokens_used: 145 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I don't have the authority to offer jobs directly. Instead, I can guide you through the process of finding a job that might be a good fit for you.\n\nCould you tell me a bit about your background, skills, and what type of job you're interested in? This will help me provide more tailored advice or suggestions. Additionally, have you considered using job search platforms like LinkedIn or Indeed, or networking with people in your desired field?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28694]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 96 
prompt_tokens_used: 28 
total_tokens_used: 124 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you please tell me a bit about your background and what kind of role you're interested in? This will help me better understand how we might be able to assist you.\n\nAlso, have you had a chance to look at our current job postings or is there a specific department or position you're interested in? Let's chat more about your qualifications and interests.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28730]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 123 
prompt_tokens_used: 28 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Before we proceed, could you tell me a bit about your background and what kind of role you're interested in? This will help me understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable in a position here? \n\nAlso, have you had a chance to look at our company's current job postings or are you interested in exploring possibilities that might not be listed? Let's chat more about how your skills and interests align with our organization.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.469694 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28757]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 28 
total_tokens_used: 129 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to have a more structured conversation about potential opportunities. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how you might fit into our organization. Additionally, if you have a resume or any relevant projects you'd like to share, that would be great. Let's discuss how your skills and interests align with our company's needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28815]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 121 
prompt_tokens_used: 28 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to take a moment to discuss how we typically approach hiring here. We usually look for candidates who have a strong fit with the role and our company culture. Could you tell me a bit about your background and what makes you interested in working with us? This will help me understand how your skills and experiences align with our current or future opportunities. \n\nAlso, if you have a resume or any relevant documents, feel free to share them with me. Let's have a conversation about how you might contribute to our team.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [28911]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 28 
total_tokens_used: 126 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to have a more structured conversation about potential opportunities. Could you tell me a bit about your background, skills, and what kind of role you're interested in? This will help me better understand how you might fit into our organization. Additionally, if you have a resume or any relevant experience, feel free to share that as well. Let's discuss how your qualifications align with our current or future needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29036]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 149 
prompt_tokens_used: 28 
total_tokens_used: 177 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can provide guidance on how to find job openings and prepare for interviews.\n\nCould you tell me a bit about your background and what kind of job you're interested in? This will help me provide more tailored advice. Additionally, have you considered using job search platforms like Indeed or LinkedIn to explore available positions? \n\nIf you're new to job searching or need to improve your resume or interview skills, there are many resources available online, such as career counseling services and free training programs. Let's discuss how these might be helpful for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 1982: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29076]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 123 
prompt_tokens_used: 28 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for coming in today. I'm happy to chat with you about potential opportunities. However, I'd like to start by getting to know you a bit better. Could you tell me a little about your background, what you're interested in, and what kind of role you're looking for? This will help me understand how we might be able to assist you. \n\nAlso, have you had a chance to explore our company's culture and values? We're always looking for individuals who align well with our mission. Let's have a conversation about how your skills and interests might fit in here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 2126: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29109]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 119 
prompt_tokens_used: 28 
total_tokens_used: 147 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential job opportunities with you. However, I need to clarify that I'm not in a position to offer a job directly at this moment. Instead, I can guide you through the process of finding a job or preparing for an interview.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice or suggestions for you. Additionally, have you considered using job search platforms like LinkedIn, Indeed, or Glassdoor to explore available positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 25, in generateAudio
    exit()
  File "<frozen _sitebuiltins>", line 26, in __call__
SystemExit: None
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29163]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 128 
prompt_tokens_used: 28 
total_tokens_used: 156 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I don't have the authority to offer jobs directly. Instead, I can guide you through the process of finding a job or preparing for interviews.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice or suggestions on where to look for job openings that might suit you. Additionally, I can offer tips on how to improve your resume, cover letter, or interview skills if needed. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 25, in generateAudio
    exit()
  File "<frozen _sitebuiltins>", line 26, in __call__
SystemExit: None
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29218]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 194 
prompt_tokens_used: 28 
total_tokens_used: 222 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might suit your skills and interests.\n\nCould you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that might be relevant? This will help me provide you with more tailored advice or resources. \n\nAdditionally, have you considered using job search platforms like Indeed, LinkedIn, or Glassdoor? These sites can be very helpful in finding job openings that match your criteria. \n\nIf you're new to job searching or need more experience, there are also resources available for training and volunteering, which can be great ways to gain experience and build your network. \n\nLet's discuss these options further and see how I can assist you in your job search", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29243]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 133 
prompt_tokens_used: 28 
total_tokens_used: 161 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through some strategies that might help you in your job search.\n\nCould you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me provide more tailored advice. Additionally, have you considered using job search platforms like LinkedIn or Indeed, or perhaps attending job fairs to network with potential employers? \n\nLet's discuss these options and see how we can best support your job search efforts.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 38, in generate_conversation
    questionAudio = audioGen.generateAudio(questionText['text'])
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioGen.py", line 34, in generateAudio
    print(response.contet)
          ^^^^^^^^^^^^^^^
AttributeError: 'HttpxBinaryResponseContent' object has no attribute 'contet'. Did you mean: 'content'?
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29319]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 145 
prompt_tokens_used: 28 
total_tokens_used: 173 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'd be happy to discuss potential opportunities with you. Could you tell me a bit about your background and what type of role you're interested in? This will help me better understand how we might be able to assist you. Additionally, do you have any specific skills or experiences that you think would be valuable to our organization? \n\nAlso, have you had a chance to look at our company's current job listings or would you like some information on those? Sometimes, we have positions that aren't listed publicly yet, so it's always good to check in directly. \n\nLet's chat more about your qualifications and interests, and we can explore if there's a good fit here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29350]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 113 
prompt_tokens_used: 28 
total_tokens_used: 141 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm, but I'd like to get to know you better and understand what you're looking for in a role. Could you tell me a bit about your background, skills, and what kind of job you're interested in? This will help me see how we might be able to assist you. \n\nAlso, have you had a chance to explore our company's current job openings or is there a specific department you're interested in? Let's discuss how your skills and interests align with what we do here.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29383]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 172 
prompt_tokens_used: 28 
total_tokens_used: 200 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I appreciate your enthusiasm. However, I'd like to discuss your qualifications and how they might align with our company's needs. Could you tell me a bit about your background and what kind of role you're interested in? This will help us determine if there's a good fit for you within our organization. Additionally, if you have a resume or any relevant experience, feel free to share that as well. Let's have a conversation about how you can contribute to our team. \n\nAlso, if you're interested in learning more about how to approach job applications, I can offer some general advice. For instance, it's often helpful to tailor your application to the specific job you're applying for and to highlight your relevant skills and experiences. If you have any questions or need guidance on that, feel free to ask", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 289, in jsonable_encoder
    encoded_value = jsonable_encoder(
                    ^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29433]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 127 
prompt_tokens_used: 28 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need a bit more information from you to see how we might be able to assist you. Could you please tell me a little bit about your background, skills, and what type of job you're interested in? This will help me better understand how we can support you in your job search. \n\nAlso, have you considered creating a resume or cover letter, or perhaps looking into job search platforms like LinkedIn or Indeed? These tools can be very helpful in finding job openings that match your qualifications. Let's discuss further", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 429 Too Many Requests"
INFO:openai._base_client:Retrying request to /audio/speech in 0.382049 seconds
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 327, in app
    content = await serialize_response(
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 201, in serialize_response
    return jsonable_encoder(response_content)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 318, in jsonable_encoder
    return ENCODERS_BY_TYPE[type(obj)](obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/encoders.py", line 59, in <lambda>
    bytes: lambda o: o.decode(),
                     ^^^^^^^^^^
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29484]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 120 
prompt_tokens_used: 28 
total_tokens_used: 148 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello Thank you for reaching out. I'm happy to chat with you about potential job opportunities. However, I need to clarify that I'm not in a position to offer a job directly. Instead, I can guide you through the process of finding a job that might suit your skills and interests.\n\nCould you tell me a bit about your background, what kind of job you're looking for, and what skills or experiences you have? This will help us explore options together. Additionally, I can provide some tips on how to effectively search for jobs and prepare for interviews. How does that sound?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [29733]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 141 
prompt_tokens_used: 24 
total_tokens_used: 165 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help and support you in your search.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to exploring different industries or do you have a specific sector in mind? \n\nLastly, what do you hope to achieve in your next role? Is there something particular that you're looking for, like work-life balance, opportunities for growth, or a certain work environment? \n\nLet's chat about these things and see how we can help you find a great fit", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 94 
prompt_tokens_used: 24 
total_tokens_used: 118 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any specific industries you're interested in? This will help me understand how I can assist you better. \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? Knowing this can help us explore more options together.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 86 
prompt_tokens_used: 24 
total_tokens_used: 110 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help and support you in your search.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are there any specific industries or roles that interest you? This will help us explore potential opportunities together.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 24 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and provide guidance.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help us narrow down some options and discuss potential paths forward.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 110 
prompt_tokens_used: 24 
total_tokens_used: 134 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly, let's have a conversation about your job aspirations. I'm here to help facilitate a discussion about your career goals and how we might be able to assist you in finding a suitable position.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate for that role? \n\nAlso, are there any specific industries or sectors that interest you? This will help us narrow down potential opportunities that might be a good fit for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 60 
prompt_tokens_used: 24 
total_tokens_used: 84 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Let's have a friendly conversation about your job search. I'm here to help you explore opportunities that might be a good fit for you.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for? Are there any specific industries or roles that interest you?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [45479]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 160 
prompt_tokens_used: 24 
total_tokens_used: 184 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n---\n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're interested in? Are there any specific industries or roles that appeal to you?\n\n**Follow-up Questions:**\n1. What skills do you think are your strongest assets for a job?\n2. Are you open to different types of work environments, such as remote or in-office positions?\n3. What are your long-term career goals, and how does this job fit into your overall vision?\n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47059]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 101 
prompt_tokens_used: 24 
total_tokens_used: 125 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in finding the right opportunity.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for, and what skills or experiences do you have that you think would be valuable in a role?\n\nAlso, are there any specific industries or sectors that interest you? This will help us narrow down some options and explore potential job openings that might be a good fit for you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47277]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 106 
prompt_tokens_used: 24 
total_tokens_used: 130 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly Let\'s have a friendly conversation about job opportunities. I\'d love to hear more about what you\'re looking for in a role. Could you tell me a bit about your interests and skills? Are you open to different types of positions, or do you have something specific in mind? \n\nAlso, I noticed there are various "Pretty Please" related job listings available, such as those at Pretty Please Boutique or Pretty Please Collective. Are any of these roles or industries appealing to you? Let\'s explore some options together', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 166 
prompt_tokens_used: 24 
total_tokens_used: 190 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly I'd be happy to engage in a mock interview with you. Let's get started!\n\n---\n\n**Interviewer:** Good morning, thank you for coming in today. Can you start by telling me a little bit about yourself and why you're interested in this role?\n\n**Please respond as the interviewee.**\n\n---\n\nAfter your response, I can guide the conversation further based on your interests and qualifications. \n\nAlso, if you're interested in specific job openings, I can provide some general information. For example, **Pretty Please Fashion** has positions available in locations like Palm Desert and Coronado, California, and Scottsdale, Arizona[1]. If you're looking for something different, there are also various **Pretty Please Boutique** jobs listed on job boards[2]. Let me know how I can assist you", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 126 
prompt_tokens_used: 24 
total_tokens_used: 150 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. \n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're looking for? What are your interests and skills that you think would be valuable in a role?\n\n**Follow-up Questions:**\n1. What specific industry or sector are you interested in?\n2. Do you have any relevant experience or education that aligns with your job goals?\n3. Are you open to different types of work environments, such as remote or in-office positions?\n\nLet's explore these questions together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47332]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 88 
prompt_tokens_used: 24 
total_tokens_used: 112 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're interested in? What skills or experiences do you think would make you a strong candidate for a position? \n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help me better understand how I can assist you in finding a job that suits your interests and skills.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [47502]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/speechAPI.py", line 30, in generate_conversation
    questionText = textGen.generateText(
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/utils/textGen.py", line 50, in generateText
    response = client.chat.completions.create(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: <html>
<head><title>401 Authorization Required</title></head>
<body>
<center><h1>401 Authorization Required</h1></center>
<hr><center>openresty/1.25.3.1</center>
<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'90ee96ef2d5e1167',t:'MTczOTA0ODg0OS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
</html>
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [6756]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 401 Unauthorized"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/speechAPI.py", line 30, in generate_conversation
    questionText = textGen.generateText(
  File "/Users/abbyandam/Documents/MadThoughts/tartan-hacks-25/Backend/utils/textGen.py", line 50, in generateText
    response = client.chat.completions.create(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py", line 863, in create
    return self._post(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 960, in request
    return self._request(
  File "/Users/abbyandam/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: <html>
<head><title>401 Authorization Required</title></head>
<body>
<center><h1>401 Authorization Required</h1></center>
<hr><center>openresty/1.25.3.1</center>
<script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'90ee97970c2661a2',t:'MTczOTA0ODg3Ni4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body>
</html>
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [6916]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 62 
prompt_tokens_used: 24 
total_tokens_used: 86 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any relevant experiences you have? This will help me understand how I can assist you in finding the right opportunity.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 139 
prompt_tokens_used: 24 
total_tokens_used: 163 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help and provide information that might be useful to you.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that you think would be relevant? Are you interested in a specific industry or role? \n\nAlso, are you open to different locations, or do you have a preference for a particular area? \n\nLastly, what are your long-term career goals, and how does this job fit into your overall vision? \n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50179]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 24 
total_tokens_used: 122 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help facilitate a mock interview or discuss potential job opportunities. Could you tell me a bit about yourself and what kind of job you're interested in? This will help us tailor the conversation to your needs and interests. \n\nAlso, are there any specific industries or roles you're considering? This could be anything from retail, tech, healthcare, or something else entirely. Let me know, and we can explore options together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50303]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 125 
prompt_tokens_used: 24 
total_tokens_used: 149 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Let's have a friendly conversation about your job search. I'm here to help you explore opportunities that might fit your skills and interests.\n\n**Can you tell me a bit about yourself?** What kind of job are you looking for, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or roles that interest you? For example, some people are interested in creative fields like design or writing, while others might prefer more technical roles like engineering or data analysis.\n\nLastly, are you open to different types of work arrangements, such as remote work or part-time positions?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Finished server process [50330]
ERROR:uvicorn.error:Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1512, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1505, in uvloop.loop.Loop.run_until_complete
  File "uvloop/loop.pyx", line 1379, in uvloop.loop.Loop.run_forever
  File "uvloop/loop.pyx", line 557, in uvloop.loop.Loop._run
  File "uvloop/loop.pyx", line 476, in uvloop.loop.Loop._on_idle
  File "uvloop/cbhandles.pyx", line 83, in uvloop.loop.Handle._run
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/server.py", line 69, in serve
    with self.capture_signals():
         ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/server.py", line 330, in capture_signals
    signal.raise_signal(captured_signal)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/runners.py", line 157, in _on_sigint
    raise KeyboardInterrupt()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 700, in lifespan
    await receive()
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/lifespan/on.py", line 137, in receive
    return await self.receive_queue.get()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/asyncio/queues.py", line 158, in get
    await getter
asyncio.exceptions.CancelledError

INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 82 
prompt_tokens_used: 24 
total_tokens_used: 106 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course, let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n**Can you tell me a bit about yourself? What kind of job are you interested in?**\n\nAlso, are there any specific industries or roles that you've been considering? This will help us tailor our conversation to your interests and goals.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50380]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 102 
prompt_tokens_used: 24 
total_tokens_used: 126 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in any way I can.\n\n**Can you tell me a little bit about yourself?** What kind of job are you looking for, and what skills or experiences do you have that you think would be relevant?\n\nAlso, **what motivates you** in your career, and **what kind of work environment** do you prefer? This will help me understand your needs better and provide more tailored advice.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50480]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 131 
prompt_tokens_used: 24 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. I'm here to help you explore potential roles that might suit your skills and interests.\n\nTo start, could you tell me a bit about yourself? What kind of job are you looking for, and what skills or experiences do you have that you think would be valuable in a role? \n\nAlso, are you open to different types of positions, such as part-time, full-time, or freelance work? \n\nLastly, is there a specific industry or sector that interests you the most? \n\nLet's chat about these details to see how we can help you find a job that fits your needs.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50501]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 127 
prompt_tokens_used: 24 
total_tokens_used: 151 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a career.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you have that you think would be valuable in that role?\n\nAlso, are you open to different types of positions, such as part-time, full-time, or freelance work? And are there any specific industries or sectors that interest you? \n\nLet's chat about your goals and see how we can help you find a job that fits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50548]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 100 
prompt_tokens_used: 24 
total_tokens_used: 124 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Could you tell me a bit about yourself and what kind of job you're looking for? What are your interests, skills, or any specific industries you're interested in? This will help me understand how I can assist you better. \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? And are there any specific locations you prefer? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50609]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 149 
prompt_tokens_used: 24 
total_tokens_used: 173 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Here are a few questions to get us started:\n\n1. **What type of job are you looking for?** Are you interested in a specific industry or role?\n\n2. **What skills do you have?** Share any relevant skills or experiences you think would be valuable in a job.\n\n3. **What are your long-term career goals?** Are there any specific positions or industries you hope to be in five years from now?\n\n4. **Are you open to different locations?** Would you prefer to work in a specific city or are you flexible about moving?\n\nLet's chat about these points and see how we can help you find a job that fits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [50660]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 70 
prompt_tokens_used: 24 
total_tokens_used: 94 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51040]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 197 
prompt_tokens_used: 1197 
total_tokens_used: 1394 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like you're looking for a job, and I can provide some guidance on where to find opportunities. Here are a few options:\n\n1. **Pretty Please Fashion**:\n   - They have a few job openings, including a **Hat Artist** in Palm Desert, CA, and a **Store Manager** in Coronado, CA. Another position is for a **Delivery Driver/Warehouse** in Scottsdale, AZ[1].\n\n2. **Pretty Please Aesthetics**:\n   - Currently, they are not hiring, but you can submit your resume for future consideration. They are based in Sacramento and Roseville[3].\n\n3. **General Job Search**:\n   - You can explore a wide range of jobs on platforms like Indeed, which lists numerous positions across different industries, including retail, beauty, and more[2].\n\nIf you're interested in a specific field or location, you might want to tailor your search accordingly. Good luck with your job search", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51379]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 147 
prompt_tokens_used: 24 
total_tokens_used: 171 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job search. I'm here to help and support you in finding the right opportunity.\n\n**Interviewer:** Hi there It's great to meet you. Can you tell me a bit about yourself and what kind of job you're looking for? What are your interests and skills that you think would be valuable in a role?\n\n**Follow-up Questions:**\n- What specific industry or sector are you interested in?\n- Do you have any previous work experience or education that you think is relevant?\n- Are there any particular skills or areas you'd like to develop further in your career?\n\nLet's chat about these and see how we can help you find a job that fits your goals", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51395]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 194 
prompt_tokens_used: 24 
total_tokens_used: 218 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. Here's how we can approach this:\n\n1. **Introduction**: Could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you bring to the table?\n\n2. **Job Preferences**: Are you looking for something specific, like a role in a particular industry or a certain type of work environment?\n\n3. **Skills and Strengths**: What are your greatest strengths and skills that you think would be valuable in a job?\n\n4. **Career Goals**: What are your long-term career goals, and how does this job fit into your overall vision?\n\n5. **Availability and Flexibility**: Are you available to start immediately, or do you have specific timing in mind? Are you open to different types of employment, such as part-time or freelance work?\n\nLet's explore these questions together to see how we can find a good fit for you", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51473]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 156 
prompt_tokens_used: 24 
total_tokens_used: 180 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help facilitate a discussion that might lead to some insights or opportunities.\n\n## Conversation Starters\n\n1. **Background and Interests**: Could you tell me a bit about your educational background and what kind of work or industry you're interested in?\n\n2. **Skills and Experience**: What skills or experiences do you think would be most valuable in your desired role?\n\n3. **Job Preferences**: Are you looking for something specific like remote work, part-time, or full-time opportunities?\n\n4. **Career Goals**: What are your short-term and long-term career goals?\n\n5. **Available Opportunities**: Are there any specific job openings or companies you've been considering?\n\nLet's explore these topics together", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51651]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 173 
prompt_tokens_used: 24 
total_tokens_used: 197 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. I'd like to explore what kind of role you're interested in and see if there's a good fit.\n\n1. **What type of job are you looking for?** Are you interested in a specific industry or role, such as retail, tech, or something creative?\n\n2. **What skills do you bring to the table?** Highlighting your strengths and experiences can help us narrow down potential opportunities.\n\n3. **Are you open to different locations?** Some jobs might require relocation or remote work. Let's discuss your preferences.\n\n4. **What are your long-term career goals?** Understanding where you want to be in the future can help guide our conversation about current opportunities.\n\nLet's chat about these points and see how we can assist you in finding a job that suits your needs", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51689]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 90 
prompt_tokens_used: 24 
total_tokens_used: 114 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore potential opportunities.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to different types of roles or industries, or do you have something specific in mind? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [51757]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 172 
prompt_tokens_used: 24 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help facilitate a mock interview or discuss job opportunities with you. How can I assist you today? Are you looking for advice on finding a job, or would you like to practice an interview scenario? \n\nHere are a few options we could explore:\n\n1. **Job Search Tips**: We could discuss strategies for finding the right job, including resume building, networking, and interview preparation.\n   \n2. **Mock Interview**: If you're preparing for an interview, we can simulate a real interview scenario. This can help you practice answering common interview questions and improve your confidence.\n\n3. **Career Advice**: If you're unsure about which career path to take, we can explore different fields and discuss what might be a good fit for you.\n\nLet me know which direction you'd like to take", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52162]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 98 
prompt_tokens_used: 24 
total_tokens_used: 122 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities that might be a good fit for you.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are there any specific industries or roles that you're particularly drawn to? This will help us narrow down some options that might suit you well.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 60, in transcribe_user_speech
    transcription = audioStore.transcribeAudio(f"./user_audio_files/{file.filename}")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioStore.py", line 35, in transcribeAudio
    phrases = silence.split_on_silence(audio, min_silence_len=600, silence_thresh=-32)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 150, in split_on_silence
    in detect_nonsilent(audio_segment, min_silence_len, silence_thresh, seek_step)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 86, in detect_nonsilent
    silent_ranges = detect_silence(audio_segment, min_silence_len, silence_thresh, seek_step)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/silence.py", line 26, in detect_silence
    silence_thresh = db_to_float(silence_thresh) * audio_segment.max_possible_amplitude
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'numpy.ndarray' object has no attribute 'max_possible_amplitude'
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 131 
prompt_tokens_used: 24 
total_tokens_used: 155 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help facilitate a discussion that might lead to some great opportunities.\n\nTo start, could you tell me a bit about yourself? What kind of job or industry are you interested in? What skills or experiences do you bring to the table? \n\nAlso, are you open to different types of roles, such as part-time, full-time, or freelance work? \n\nLastly, what are your long-term career goals, and how does this job fit into your overall vision? \n\nFeel free to share as much or as little as you like, and we can go from there", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52213]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 83 
prompt_tokens_used: 24 
total_tokens_used: 107 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation. I'm here to help you explore potential job opportunities. Could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you have that might be relevant? \n\nAlso, are you open to different types of roles or industries, or do you have something specific in mind? \n\nLet's chat about it", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52410]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 91 
prompt_tokens_used: 24 
total_tokens_used: 115 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\n**Can you tell me a bit about yourself?** What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate?\n\nAlso, are there any specific industries or sectors that interest you? This could help us narrow down some potential opportunities.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
ERROR:uvicorn.error:Exception in ASGI application
Traceback (most recent call last):
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/protocols/http/httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/speechAPI.py", line 60, in transcribe_user_speech
    transcription = audioStore.transcribeAudio(f"./user_audio_files/{file.filename}")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/Desktop/projects/tartan-hacks-25/Backend/utils/audioStore.py", line 63, in transcribeAudio
    phrase.export(phrase_audio_file_path, bitrate='256k', format="wav")
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/audio_segment.py", line 867, in export
    out_f, _ = _fd_or_path_or_tempfile(out_f, 'wb+')
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/elizabethterveen/anaconda3/envs/tartan-hacks-25/lib/python3.12/site-packages/pydub/utils.py", line 60, in _fd_or_path_or_tempfile
    fd = open(fd, mode=mode)
         ^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '../phrases/phrase0.wav'
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 93 
prompt_tokens_used: 24 
total_tokens_used: 117 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Of course Let's have a friendly conversation about your job aspirations. I'm here to help you explore opportunities and discuss what you're looking for in a role.\n\nTo start, could you tell me a bit about yourself? What kind of job are you interested in, and what skills or experiences do you think would make you a strong candidate? \n\nAlso, are you open to different types of positions or industries, or do you have something specific in mind?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52444]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 276 
prompt_tokens_used: 24 
total_tokens_used: 300 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Certainly Let's have a friendly conversation about job opportunities. Here's a neutral and engaging approach:\n\n---\n\n**Interviewer:** Hi there Thank you for coming in today. I understand you're looking for a job, and I'd be happy to help explore some options with you. Can you tell me a bit about yourself and what kind of job you're interested in?\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Follow-up:** That sounds great Let's see if we can match your skills and interests with some available positions. Are you open to working in different industries, or do you have a specific sector in mind?\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Follow-up:** Excellent Based on what you've shared, I think we might have a few opportunities that could be a good fit. Let me show you some job listings that might interest you. (Present some relevant job listings)\n\n**Interviewee Response:** (Insert their response here)\n\n**Interviewer Conclusion:** It was great chatting with you If you have any more questions or would like to proceed with any of these opportunities, feel free to let me know. We're here to help.\n\n---\n\nThis approach is designed to be friendly and exploratory, helping to identify the interviewee's interests and skills while offering support in finding a suitable job.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52520]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 39 
prompt_tokens_used: 1216 
total_tokens_used: 1255 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your sentence is incomplete or unclear. Could you please provide more context or clarify what you are trying to express? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 36 
prompt_tokens_used: 1207 
total_tokens_used: 1243 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking for? I'm here to help with any information or assistance you need.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 31 
prompt_tokens_used: 1207 
total_tokens_used: 1238 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="It seems like your query is incomplete. Could you please provide more details or clarify what you are asking? I'll do my best to assist you.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52737]
INFO:httpx:HTTP Request: POST https://api.perplexity.ai/chat/completions "HTTP/1.1 200 OK"
INFO:utils.textGen:received a response from perplexity. 
completion_tokens_used: 114 
prompt_tokens_used: 82 
total_tokens_used: 196 

INFO:utils.textGen:potential choice from perplexity

INFO:utils.textGen:Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content="Hello It's great to meet you. You're a computer science major looking for employment opportunities, and you're here today to explore potential job openings with our company. You seem eager to find a position that aligns with your skills and interests.\n\nTo summarize, you've expressed your enthusiasm for being employed and are hoping to find a suitable role within our organization. Let's take a moment to discuss your background and how your skills might fit into our current projects. Can you tell me a bit more about your experiences and what you're most interested in working on?", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), delta={'role': 'assistant', 'content': ''})
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
INFO:uvicorn.error:Shutting down
INFO:uvicorn.error:Waiting for application shutdown.
INFO:uvicorn.error:Application shutdown complete.
INFO:uvicorn.error:Finished server process [52839]
